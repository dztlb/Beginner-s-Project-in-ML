# é£ç”µåŠŸç‡é¢„æµ‹é¡¹ç›®è¯¦ç»†è¯´æ˜æ–‡æ¡£

## ä¸€ã€é¡¹ç›®èƒŒæ™¯æè¿°

### 1.1 é¡¹ç›®èƒŒæ™¯
é•¿æœŸä»¥æ¥ï¼Œäººç±»ç¤¾ä¼šä¾èµ–åŒ–çŸ³ç‡ƒæ–™ä½œä¸ºä¸»è¦èƒ½æºï¼ŒåŒ–çŸ³ç‡ƒæ–™çš„é•¿æœŸä½¿ç”¨å¯¼è‡´äº†èµ„æºæ¯ç«­ã€ç©ºæ°”æ±¡æŸ“ç­‰ä¸€ç³»åˆ—é—®é¢˜ã€‚é£åŠ›å‘ç”µä½œä¸ºå…¸å‹çš„å¯å†ç”Ÿèƒ½æºä¹‹ä¸€ï¼Œåœ¨ç”µåŠ›ç³»ç»Ÿæ€»å‘ç”µé‡ä¸­æ‰€å çš„æ¯”ä¾‹é€å¹´ä¸Šå‡ã€‚

ä¸ä¼ ç»Ÿå‘ç”µæŠ€æœ¯ç›¸æ¯”ï¼Œç”±äºé£èƒ½çš„å­£èŠ‚æ€§ã€é—´æ¥æ€§å’Œéšæœºæ³¢åŠ¨æ€§ç­‰ç‰¹ç‚¹ï¼Œæ‰€ä»¥é£ç”µæ˜¯ä¸€ç§ä¸ç¨³å®šçš„èƒ½æºã€‚é£åŠ›å‘ç”µçš„ä¸ç¨³å®šæ€§å¢åŠ äº†é£ç”µåŠŸç‡çš„é¢„æµ‹éš¾åº¦ï¼Œç»™ç”µåŠ›ç³»ç»Ÿçš„ç»æµæ€§ã€ç¨³å®šæ€§å’Œå®‰å…¨æ€§å¸¦æ¥æ–°çš„é—®é¢˜ã€‚

å› æ­¤ï¼Œæé«˜é£ç”µåŠŸç‡é¢„æµ‹çš„å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§ï¼Œå¯¹äºä¿è¯ç”µåŠ›ç³»ç»Ÿçš„å¹³ç¨³è¿è¡Œã€ä¼˜åŒ–é£ç”µè¿è¡Œæˆæœ¬ååˆ†é‡è¦ã€‚

### 1.2 é¡¹ç›®ä»»åŠ¡è¦æ±‚
æœ¬é¡¹ç›®æ—¨åœ¨å®ç°é£ç”µåŠŸç‡çš„ç²¾å‡†é¢„æµ‹ï¼Œä¸»è¦ä»»åŠ¡åŒ…æ‹¬ï¼š

1. **æ•°æ®è´¨é‡æå‡**ï¼šå¤„ç†é£ç”µæ•°æ®ä¸­çš„ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ï¼Œæé«˜æ•°æ®è´¨é‡
2. **ç‰¹å¾å·¥ç¨‹ä¼˜åŒ–**ï¼šé€šè¿‡å¤šç§ç‰¹å¾æå–å’Œé€‰æ‹©æ–¹æ³•ï¼ŒæŒ–æ˜æ•°æ®ä¸­çš„æ½œåœ¨å…³ç³»
3. **ä¿¡å·åˆ†è§£å¤„ç†**ï¼šä½¿ç”¨CEEMDANå¯¹éå¹³ç¨³åŠŸç‡æ•°æ®è¿›è¡Œåˆ†è§£ï¼Œä¼˜åŒ–åˆ†è§£è¿‡ç¨‹
4. **æ·±åº¦å­¦ä¹ å»ºæ¨¡**ï¼šæ„å»ºåŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹
5. **é¢„æµ‹ç²¾åº¦æå‡**ï¼šé€šè¿‡å¤šå±‚æ¬¡çš„ä¼˜åŒ–ç­–ç•¥ï¼Œæé«˜é£ç”µåŠŸç‡é¢„æµ‹çš„å‡†ç¡®æ€§

### 1.3 é¡¹ç›®æ„ä¹‰
- **æŠ€æœ¯ä»·å€¼**ï¼šæ¢ç´¢é£ç”µåŠŸç‡é¢„æµ‹çš„æ–°æ–¹æ³•ï¼Œæå‡é¢„æµ‹ç²¾åº¦
- **ç»æµä»·å€¼**ï¼šä¼˜åŒ–é£ç”µè¿è¡Œæˆæœ¬ï¼Œæé«˜ç”µåŠ›ç³»ç»Ÿç»æµæ€§
- **ç¤¾ä¼šä»·å€¼**ï¼šä¿ƒè¿›å¯å†ç”Ÿèƒ½æºå‘å±•ï¼Œå‡å°‘ç¯å¢ƒæ±¡æŸ“
- **å­¦æœ¯ä»·å€¼**ï¼šä¸ºæ—¶é—´åºåˆ—é¢„æµ‹å’Œæ·±åº¦å­¦ä¹ åº”ç”¨æä¾›æ–°æ€è·¯

## äºŒã€æ•°æ®é›†

### 2.1 æ•°æ®é›†æ¦‚è¿°
æœ¬é¡¹ç›®ä½¿ç”¨çš„æ•°æ®é›†ä¸ºé£ç”µåœºçš„å®é™…è¿è¡Œæ•°æ®ï¼ŒåŒ…å«æ—¶é—´åºåˆ—çš„æ°”è±¡å‚æ•°å’Œå¯¹åº”çš„å‘ç”µåŠŸç‡æ•°æ®ã€‚æ•°æ®é›†æ¶µç›–äº†é£åŠ›å‘ç”µè¿‡ç¨‹ä¸­çš„å…³é”®å½±å“å› ç´ ï¼Œä¸ºæ„å»ºå‡†ç¡®çš„é¢„æµ‹æ¨¡å‹æä¾›äº†å……åˆ†çš„æ•°æ®æ”¯æ’‘ã€‚

### 2.2 æ•°æ®å†…å®¹
æ•°æ®é›†åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- **DATETIME**: æ—¶é—´æˆ³ï¼Œè®°å½•æ•°æ®é‡‡é›†çš„å…·ä½“æ—¶é—´
- **WINDDIRECTION**: é£å‘ï¼Œè¡¨ç¤ºé£çš„ä¸»è¦æ¥å‘
- **TEMPERATURE**: æ¸©åº¦ï¼Œç¯å¢ƒæ¸©åº¦æ•°æ®
- **HUMIDITY**: æ¹¿åº¦ï¼Œç¯å¢ƒæ¹¿åº¦æ•°æ®
- **PRESSURE**: æ°”å‹ï¼Œå¤§æ°”å‹åŠ›æ•°æ®
- **WINDSPEED**: é£é€Ÿï¼Œé£åŠ›å¤§å°
- **POWER**: åŠŸç‡ï¼Œé£åŠ›å‘ç”µçš„å®é™…è¾“å‡ºåŠŸç‡ï¼ˆç›®æ ‡å˜é‡ï¼‰

### 2.3 æ•°æ®ç‰¹ç‚¹
- **æ•°æ®è§„æ¨¡**: çº¦89,773æ¡è®°å½•
- **æ—¶é—´è·¨åº¦**: è¦†ç›–å¤šä¸ªæ—¶é—´å‘¨æœŸçš„è¿ç»­è§‚æµ‹æ•°æ®
- **æ•°æ®è´¨é‡**: åŒ…å«éƒ¨åˆ†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ï¼Œéœ€è¦è¿›è¡Œé¢„å¤„ç†
- **æ—¶åºç‰¹æ€§**: å…·æœ‰æ˜æ˜¾çš„æ—¶é—´åºåˆ—ç‰¹å¾ï¼Œéœ€è¦è€ƒè™‘æ—¶é—´ä¾èµ–æ€§
- **éå¹³ç¨³æ€§**: åŠŸç‡æ•°æ®å…·æœ‰éå¹³ç¨³ç‰¹æ€§ï¼Œéœ€è¦è¿›è¡Œç›¸åº”çš„å¤„ç†

### 2.4 æ•°æ®è·å–æ–¹å¼
æ•°æ®é›†å·²åŒ…å«åœ¨é¡¹ç›®æ–‡ä»¶ä¸­ï¼Œä½äº`data/é¡¹ç›®2-0.csv`ã€‚ç”¨æˆ·å¯ä»¥ç›´æ¥ä½¿ç”¨è¯¥æ•°æ®é›†è¿›è¡Œé¡¹ç›®å¤ç°ï¼Œæ— éœ€é¢å¤–ä¸‹è½½ã€‚

**æ•°æ®æ–‡ä»¶è·¯å¾„**: `data/é¡¹ç›®2-0.csv`
**æ•°æ®æ–‡ä»¶å¤§å°**: çº¦89,773æ¡è®°å½•
**æ•°æ®æ ¼å¼**: CSVæ ¼å¼ï¼ŒUTF-8ç¼–ç 

### 2.5 æ•°æ®é¢„å¤„ç†è¦æ±‚
æ ¹æ®æ‘˜è¦æè¿°ï¼Œéœ€è¦å¯¹æ•°æ®è¿›è¡Œä»¥ä¸‹é¢„å¤„ç†ï¼š
1. **ç›¸å…³æ€§åˆ†æ**: ä½¿ç”¨çš®å°”é€Šç›¸å…³ç³»æ•°åˆ†ææ°”è±¡å› ç´ ä¸é£ç”µåŠŸç‡çš„å…³ç³»
2. **å¹³ç¨³æ€§æ£€éªŒ**: ä½¿ç”¨KPSSæ£€éªŒåŠŸç‡æ•°æ®çš„å¹³ç¨³æ€§
3. **ç¼ºå¤±å€¼å¤„ç†**: é‡‡ç”¨æ»‘åŠ¨çª—å£å‡å€¼æ’è¡¥æ³•å¤„ç†ç¼ºå¤±å€¼
4. **å¼‚å¸¸å€¼æ£€æµ‹**: ä½¿ç”¨å­¤ç«‹æ£®æ—æ–¹æ³•è¿›è¡Œå¼‚å¸¸æ£€æµ‹
5. **å¼‚å¸¸å€¼ä¿®æ­£**: ä½¿ç”¨æ”¯æŒå‘é‡æœºå¯¹å¼‚å¸¸å€¼è¿›è¡Œä¿®æ­£

## ä¸‰ã€æ¨¡å‹ä»‹ç»

### 3.1 æ•°æ®å¤„ç†æ–¹æ³•

#### 3.1.1 ç›¸å…³æ€§åˆ†æ
- **çš®å°”é€Šç›¸å…³ç³»æ•°**: ç”¨äºåˆ†ææ°”è±¡å› ç´ ä¸é£ç”µåŠŸç‡ä¹‹é—´çš„çº¿æ€§ç›¸å…³å…³ç³»
- **KPSSå¹³ç¨³æ€§æ£€éªŒ**: æ£€éªŒåŠŸç‡æ•°æ®çš„å¹³ç¨³æ€§ï¼Œè¯†åˆ«éå¹³ç¨³ç‰¹æ€§

#### 3.1.2 ç¼ºå¤±å€¼å¤„ç†
- **æ»‘åŠ¨çª—å£å‡å€¼æ’è¡¥æ³•**: ç»“åˆé£åŠ›å‘ç”µæ•°æ®çš„æ—¶åºæ€§ç‰¹ç‚¹ï¼Œä½¿ç”¨æ»‘åŠ¨çª—å£è®¡ç®—å‡å€¼æ¥å¡«å……ç¼ºå¤±å€¼
- **ä¼˜åŠ¿**: ä¿æŒæ•°æ®çš„æ—¶åºè¿ç»­æ€§ï¼Œé¿å…å¼•å…¥ä¸åˆç†çš„å›ºå®šå€¼

#### 3.1.3 å¼‚å¸¸å€¼å¤„ç†
- **å­¤ç«‹æ£®æ—å¼‚å¸¸æ£€æµ‹**: ä½¿ç”¨å­¤ç«‹æ£®æ—ç®—æ³•è¯†åˆ«æ•°æ®ä¸­çš„å¼‚å¸¸å€¼
- **æ”¯æŒå‘é‡æœºä¿®æ­£**: åŸºäºé£é€Ÿå’ŒåŠŸç‡çš„æ‹Ÿåˆæ¨¡å‹ï¼Œä½¿ç”¨SVMå¯¹å¼‚å¸¸å€¼è¿›è¡Œä¿®æ­£
- **ä¼˜åŠ¿**: èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å’Œä¿®æ­£å„ç§ç±»å‹çš„å¼‚å¸¸å€¼ï¼Œæé«˜æ•°æ®è´¨é‡

### 3.2 ç‰¹å¾å·¥ç¨‹æ–¹æ³•

#### 3.2.1 ç‰¹å¾æå–
- **æ»åç‰¹å¾**: æå–å†å²æ—¶é—´ç‚¹çš„ç‰¹å¾å€¼ï¼Œæ•æ‰æ—¶é—´ä¾èµ–æ€§
- **æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾**: è®¡ç®—æ»‘åŠ¨çª—å£å†…çš„ç»Ÿè®¡é‡ï¼ˆå‡å€¼ã€æ ‡å‡†å·®ã€æœ€å¤§å€¼ã€æœ€å°å€¼ç­‰ï¼‰
- **è¿ç»­å°æ³¢å˜æ¢(CWT)**: å¯¹æ—¶é—´åºåˆ—æ•°æ®è¿›è¡Œå°æ³¢å˜æ¢ï¼Œæå–é¢‘åŸŸç‰¹å¾
- **æ—¶é—´ç‰¹å¾**: æå–å°æ—¶ã€æ—¥æœŸã€æœˆä»½ã€æ˜ŸæœŸç­‰æ—¶é—´ç›¸å…³ä¿¡æ¯

#### 3.2.2 ç‰¹å¾é€‰æ‹©
- **é€’å½’ç‰¹å¾æ¶ˆé™¤äº¤å‰éªŒè¯(RFECV)**: è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç‰¹å¾å­é›†ï¼Œå»é™¤å†—ä½™å’Œä¸ç›¸å…³ç‰¹å¾
- **ä¼˜åŠ¿**: é™ä½è¿‡æ‹Ÿåˆé£é™©ï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›

### 3.3 ä¿¡å·åˆ†è§£æ–¹æ³•

#### 3.3.1 CEEMDANåˆ†è§£
- **åŸç†**: å®Œå…¨é›†åˆç»éªŒæ¨¡æ€åˆ†è§£è‡ªé€‚åº”å™ªå£°ï¼Œå°†éå¹³ç¨³åŠŸç‡æ•°æ®åˆ†è§£ä¸ºå¤šä¸ªæœ¬å¾æ¨¡æ€å‡½æ•°(IMF)å’Œæ®‹ä½™ä¿¡å·
- **ä¼˜åŠ¿**: èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†éçº¿æ€§å’Œéå¹³ç¨³æ—¶é—´åºåˆ—æ•°æ®
- **ä¼˜åŒ–**: ä½¿ç”¨è‡ªé€‚åº”æ²™ä¸é±¼ç®—æ³•ä¼˜åŒ–CEEMDANçš„åˆ†è§£è¿‡ç¨‹

#### 3.3.2 æ ·æœ¬ç†µåˆ†æ
- **ç›®çš„**: è®¡ç®—æ¯ä¸ªIMFçš„æ ·æœ¬ç†µï¼Œå°†ç†µå€¼ä½äºåŠŸç‡ç†µå€¼çš„IMFè¿›è¡Œåˆå¹¶
- **æ•ˆæœ**: å‡å°‘åç»­æ¨¡å‹çš„é¢„æµ‹æ—¶é—´ï¼Œæé«˜è®¡ç®—æ•ˆç‡

### 3.4 æ·±åº¦å­¦ä¹ æ¨¡å‹æ¶æ„

#### 3.4.1 åŸºç¡€æ¨¡å‹ï¼šCNN-BiGRU
- **å·ç§¯ç¥ç»ç½‘ç»œ(CNN)**: ç”¨äºç‰¹å¾æå–ï¼Œæ•æ‰å±€éƒ¨ç‰¹å¾æ¨¡å¼
- **åŒå‘GRU**: å¼ºåŒ–æ—¶é—´åºåˆ—ç‰¹å¾çš„å­¦ä¹ æ•ˆæœï¼Œæ•æ‰åŒå‘æ—¶é—´ä¾èµ–å…³ç³»
- **è‡ªæ³¨æ„åŠ›æœºåˆ¶**: æ•æ‰é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œæé«˜æ¨¡å‹è¡¨è¾¾èƒ½åŠ›

#### 3.4.2 ä¼˜åŒ–æ¨¡å‹ï¼šTCN-å¤šå¤´æ³¨æ„åŠ›-BiGRU
- **æ—¶åºå·ç§¯ç½‘ç»œ(TCN)**: æ›¿ä»£åŸæœ‰CNNï¼Œå¢å¼ºå¹¶è¡Œå¤„ç†èƒ½åŠ›å’Œæ„Ÿå—é‡çµæ´»æ€§
- **å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶**: æ›¿æ¢è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°ä¿¡æ¯çš„é«˜æ•ˆå¤„ç†
- **ä¼˜åŠ¿**: æ›´å¥½çš„å¹¶è¡Œæ€§èƒ½ï¼Œæ›´å¼ºçš„ç‰¹å¾æå–èƒ½åŠ›

### 3.5 è‡ªé€‚åº”æ²™ä¸é±¼ç¾¤ä¼˜åŒ–ç®—æ³•

#### 3.5.1 ç®—æ³•åŸç†
è‡ªé€‚åº”æ²™ä¸é±¼ç¾¤ä¼˜åŒ–ç®—æ³•(Adaptive Sardine Swarm Optimization, ASSO)æ˜¯ä¸€ç§åŸºäºç¾¤ä½“æ™ºèƒ½çš„å…ƒå¯å‘å¼ä¼˜åŒ–ç®—æ³•ï¼Œæ¨¡æ‹Ÿæ²™ä¸é±¼ç¾¤åœ¨æµ·æ´‹ä¸­çš„è§…é£Ÿè¡Œä¸ºã€‚

#### 3.5.2 ç®—æ³•ç‰¹ç‚¹
- **è‡ªé€‚åº”å‚æ•°è°ƒæ•´**: æ ¹æ®æœç´¢è¿‡ç¨‹åŠ¨æ€è°ƒæ•´æœç´¢å‚æ•°
- **å…¨å±€æœç´¢èƒ½åŠ›**: èƒ½å¤Ÿåœ¨å¤šç»´ç©ºé—´å†…æœç´¢æœ€ä¼˜çš„å‚æ•°ç»„åˆ
- **æ”¶æ•›é€Ÿåº¦å¿«**: ç›¸æ¯”ä¼ ç»Ÿç½‘æ ¼æœç´¢ï¼Œæ”¶æ•›é€Ÿåº¦æ˜¾è‘—æå‡
- **é²æ£’æ€§å¼º**: å¯¹åˆå§‹å‚æ•°è®¾ç½®ä¸æ•æ„Ÿï¼Œå…·æœ‰è‰¯å¥½çš„é²æ£’æ€§

#### 3.5.3 åº”ç”¨åœºæ™¯
- **CEEMDANå‚æ•°ä¼˜åŒ–**: ä¼˜åŒ–ä¿¡å·åˆ†è§£è¿‡ç¨‹çš„å‚æ•°è®¾ç½®
- **æ·±åº¦å­¦ä¹ æ¨¡å‹è¶…å‚æ•°è°ƒä¼˜**: ä¼˜åŒ–ç½‘ç»œç»“æ„å‚æ•°
- **ç‰¹å¾é€‰æ‹©å‚æ•°ä¼˜åŒ–**: ä¼˜åŒ–ç‰¹å¾å·¥ç¨‹ç›¸å…³å‚æ•°

### 3.6 æ¨¡å‹ä¼˜åŠ¿

#### 3.6.1 æ•°æ®å¤„ç†ä¼˜åŠ¿
- **å¤šç»´åº¦æ•°æ®æ¸…æ´—**: ç»“åˆå¤šç§æ–¹æ³•å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
- **æ™ºèƒ½ç‰¹å¾å·¥ç¨‹**: è‡ªåŠ¨åŒ–çš„ç‰¹å¾æå–å’Œé€‰æ‹©è¿‡ç¨‹
- **ä¿¡å·åˆ†è§£ä¼˜åŒ–**: ä½¿ç”¨ä¼˜åŒ–ç®—æ³•æå‡åˆ†è§£æ•ˆæœ

#### 3.6.2 æ¨¡å‹æ¶æ„ä¼˜åŠ¿
- **æ··åˆæ·±åº¦å­¦ä¹ **: ç»“åˆCNNã€GRUå’Œæ³¨æ„åŠ›æœºåˆ¶çš„ä¼˜åŠ¿
- **æ—¶åºå»ºæ¨¡èƒ½åŠ›**: ä¸“é—¨é’ˆå¯¹æ—¶é—´åºåˆ—æ•°æ®è®¾è®¡
- **å¹¶è¡Œè®¡ç®—æ•ˆç‡**: TCNæä¾›æ›´å¥½çš„å¹¶è¡Œæ€§èƒ½

#### 3.6.3 ä¼˜åŒ–ç®—æ³•ä¼˜åŠ¿
- **æ²™ä¸é±¼ä¼˜åŒ–ä¼˜åŠ¿**: ç›¸æ¯”ç½‘æ ¼æœç´¢ï¼Œæœç´¢æ•ˆç‡æ˜¾è‘—æå‡
- **è‡ªé€‚åº”è°ƒæ•´**: æ ¹æ®æœç´¢è¿‡ç¨‹åŠ¨æ€ä¼˜åŒ–å‚æ•°
- **å…¨å±€æœ€ä¼˜**: é¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜è§£

## å››ã€éƒ¨ç½²

### 4.1 ç¡¬ä»¶è¦æ±‚

#### 4.1.1 æœ€ä½é…ç½®
- **CPU**: Intel i5 æˆ– AMD Ryzen 5 åŠä»¥ä¸Š
- **å†…å­˜**: 8GB RAM
- **å­˜å‚¨**: 10GB å¯ç”¨ç©ºé—´
- **æ˜¾å¡**: é›†æˆæ˜¾å¡å³å¯ï¼ˆCPUè®­ç»ƒï¼‰

#### 4.1.2 æ¨èé…ç½®
- **CPU**: Intel i7 æˆ– AMD Ryzen 7 åŠä»¥ä¸Š
- **å†…å­˜**: 16GB RAM
- **å­˜å‚¨**: 20GB å¯ç”¨ç©ºé—´
- **æ˜¾å¡**: NVIDIA GTX 1060 6GB æˆ–æ›´é«˜ï¼ˆGPUåŠ é€Ÿè®­ç»ƒï¼‰

### 4.2 è½¯ä»¶ç¯å¢ƒ

#### 4.2.1 æ“ä½œç³»ç»Ÿ
- Windows 10/11
- macOS 10.14+
- Ubuntu 18.04+

#### 4.2.2 Pythonç¯å¢ƒ
- Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬

### 4.3 è½¯ä»¶éƒ¨ç½²è¯¦ç»†æ­¥éª¤

#### æ­¥éª¤1: å®‰è£…Anaconda
1. è®¿é—® https://www.anaconda.com/products/distribution
2. ä¸‹è½½å¹¶å®‰è£…Anacondaï¼ˆé€‰æ‹©Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬ï¼‰
3. å®‰è£…æ—¶ç¡®ä¿å‹¾é€‰"Add Anaconda to PATH"é€‰é¡¹
4. å®‰è£…å®Œæˆåé‡å¯å‘½ä»¤è¡Œæˆ–PowerShell

#### æ­¥éª¤2: å®‰è£…PyCharm
1. è®¿é—® https://www.jetbrains.com/pycharm/
2. ä¸‹è½½PyCharm Communityï¼ˆå…è´¹ç‰ˆï¼‰æˆ–Professionalç‰ˆ
3. å®‰è£…PyCharmï¼ŒæŒ‰ç…§å®‰è£…å‘å¯¼å®Œæˆå®‰è£…

#### æ­¥éª¤3: åˆ›å»ºAnacondaç¯å¢ƒ
```bash
# æ‰“å¼€Anaconda Promptæˆ–å‘½ä»¤è¡Œ
# åˆ›å»ºæ–°çš„condaç¯å¢ƒ
conda create -n wind_power_prediction python=3.8

# æ¿€æ´»ç¯å¢ƒ
conda activate wind_power_prediction

# éªŒè¯ç¯å¢ƒ
python --version
conda info --envs
```

#### æ­¥éª¤4: å®‰è£…é¡¹ç›®ä¾èµ–åŒ…
```bash
# ç¡®ä¿åœ¨wind_power_predictionç¯å¢ƒä¸­
conda activate wind_power_prediction

# æ–¹æ³•1: ä½¿ç”¨environment.ymlæ–‡ä»¶ä¸€é”®å®‰è£…ï¼ˆæ¨èï¼‰
conda env update -f environment.yml

# æ–¹æ³•2: æ‰‹åŠ¨å®‰è£…ä¾èµ–åŒ…
# ä½¿ç”¨condaå®‰è£…ä¸»è¦ä¾èµ–åŒ…
conda install pandas numpy matplotlib seaborn scikit-learn jupyter

# ä½¿ç”¨pipå®‰è£…æ·±åº¦å­¦ä¹ æ¡†æ¶å’Œç‰¹æ®ŠåŒ…
pip install tensorflow>=2.8.0
pip install joblib

# å®‰è£…æ–°å¢çš„ä¸“ä¸šåº“ï¼ˆç”¨äºä¿¡å·åˆ†è§£å’Œç‰¹å¾å·¥ç¨‹ï¼‰
pip install PyEMD>=0.5.0      # CEEMDANä¿¡å·åˆ†è§£
pip install PyWavelets>=1.4.0 # è¿ç»­å°æ³¢å˜æ¢ï¼ˆæ³¨æ„ï¼šåŒ…åæ˜¯PyWaveletsï¼Œå¯¼å…¥æ—¶ç”¨pywtï¼‰
pip install statsmodels>=0.13.0  # KPSSå¹³ç¨³æ€§æ£€éªŒ
pip install scipy>=1.7.0      # ç§‘å­¦è®¡ç®—åº“

# éªŒè¯å®‰è£…
python -c "import PyEMD; print('PyEMDå®‰è£…æˆåŠŸ')"
python -c "import pywt; print('pywtå®‰è£…æˆåŠŸ')"
python -c "import statsmodels; print('statsmodelså®‰è£…æˆåŠŸ')"
```

#### æ­¥éª¤5: åœ¨PyCharmä¸­é…ç½®é¡¹ç›®
1. **æ‰“å¼€PyCharm**ï¼Œé€‰æ‹©"Open"æ‰“å¼€é¡¹ç›®æ–‡ä»¶å¤¹
2. **é…ç½®Pythonè§£é‡Šå™¨**ï¼š
   - ç‚¹å‡» `File` â†’ `Settings` (Windows) æˆ– `PyCharm` â†’ `Preferences` (macOS)
   - é€‰æ‹© `Project: wind_power_prediction` â†’ `Python Interpreter`
   - ç‚¹å‡»é½¿è½®å›¾æ ‡ â†’ `Add`
   - é€‰æ‹© `Conda Environment` â†’ `Existing environment`
   - é€‰æ‹©Anacondaå®‰è£…è·¯å¾„ä¸‹çš„ç¯å¢ƒï¼š`C:\Users\[ç”¨æˆ·å]\anaconda3\envs\wind_power_prediction\python.exe`
   - ç‚¹å‡» `OK` ç¡®è®¤

3. **é…ç½®é¡¹ç›®ç»“æ„**ï¼š
   - åœ¨é¡¹ç›®çª—å£ä¸­å³é”®ç‚¹å‡»é¡¹ç›®æ ¹ç›®å½•
   - é€‰æ‹© `Mark Directory as` â†’ `Sources Root`

#### æ­¥éª¤6: éªŒè¯ç¯å¢ƒé…ç½®
é¡¹ç›®å·²æä¾›å¤šä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œå¯ä»¥ç›´æ¥è¿è¡ŒéªŒè¯ï¼š

1. **ç¯å¢ƒéªŒè¯æµ‹è¯•** (`test_environment.py`):
   - éªŒè¯Pythonç¯å¢ƒå’ŒåŸºæœ¬åŒ…å¯¼å…¥
   - æ£€æŸ¥æ·±åº¦å­¦ä¹ æ¡†æ¶å®‰è£…
   - éªŒè¯ä¿¡å·å¤„ç†åŒ…å®‰è£…

2. **ä¾èµ–åŒ…æ£€æŸ¥** (`test_dependencies.py`):
   - æ£€æŸ¥æ‰€æœ‰å¿…éœ€å’Œå¯é€‰ä¾èµ–åŒ…
   - æ˜¾ç¤ºåŒ…ç‰ˆæœ¬ä¿¡æ¯
   - æä¾›å®‰è£…å»ºè®®

3. **å¿«é€ŸåŠŸèƒ½æµ‹è¯•** (`test_quick_mode.py`):
   - ä½¿ç”¨å°æ•°æ®é›†å¿«é€ŸéªŒè¯ä»£ç åŠŸèƒ½
   - æµ‹è¯•æ•°æ®å¤„ç†å’Œç‰¹å¾å·¥ç¨‹
   - éªŒè¯æ¨¡å‹è®­ç»ƒæµç¨‹

è¿è¡Œæµ‹è¯•æ–‡ä»¶ï¼š
```bash
# ç¯å¢ƒéªŒè¯
python test_environment.py

# ä¾èµ–åŒ…æ£€æŸ¥
python test_dependencies.py

# å¿«é€ŸåŠŸèƒ½æµ‹è¯•
python test_quick_mode.py
```
```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç¯å¢ƒé…ç½®éªŒè¯æµ‹è¯•æ–‡ä»¶
ç”¨äºéªŒè¯æ‰€æœ‰ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…
"""
import sys
import warnings
warnings.filterwarnings('ignore')

def test_basic_imports():
    """æµ‹è¯•åŸºæœ¬åŒ…çš„å¯¼å…¥"""
    print("æ­£åœ¨æµ‹è¯•åŸºæœ¬åŒ…å¯¼å…¥...")
    
    try:
        import pandas as pd
        print(f"âœ“ Pandasç‰ˆæœ¬: {pd.__version__}")
    except ImportError as e:
        print(f"âœ— Pandaså¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import numpy as np
        print(f"âœ“ Numpyç‰ˆæœ¬: {np.__version__}")
    except ImportError as e:
        print(f"âœ— Numpyå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import matplotlib
        import matplotlib.pyplot as plt
        print(f"âœ“ Matplotlibç‰ˆæœ¬: {matplotlib.__version__}")
    except ImportError as e:
        print(f"âœ— Matplotlibå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import seaborn as sns
        print(f"âœ“ Seabornç‰ˆæœ¬: {sns.__version__}")
    except ImportError as e:
        print(f"âœ— Seabornå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import sklearn
        print(f"âœ“ Scikit-learnç‰ˆæœ¬: {sklearn.__version__}")
    except ImportError as e:
        print(f"âœ— Scikit-learnå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    return True

def test_deep_learning_imports():
    """æµ‹è¯•æ·±åº¦å­¦ä¹ åŒ…å¯¼å…¥"""
    print("\næ­£åœ¨æµ‹è¯•æ·±åº¦å­¦ä¹ åŒ…å¯¼å…¥...")
    
    try:
        import tensorflow as tf
        print(f"âœ“ TensorFlowç‰ˆæœ¬: {tf.__version__}")
    except ImportError as e:
        print(f"âœ— TensorFlowå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from tensorflow import keras
        print(f"âœ“ Keraså¯ç”¨")
    except ImportError as e:
        print(f"âœ— Keraså¯¼å…¥å¤±è´¥: {e}")
        return False
    
    return True

def test_signal_processing_imports():
    """æµ‹è¯•ä¿¡å·å¤„ç†åŒ…å¯¼å…¥"""
    print("\næ­£åœ¨æµ‹è¯•ä¿¡å·å¤„ç†åŒ…å¯¼å…¥...")
    
    try:
        import PyEMD
        print(f"âœ“ PyEMDå¯ç”¨")
    except ImportError as e:
        print(f"âœ— PyEMDå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import pywt
        print(f"âœ“ PyWaveletsç‰ˆæœ¬: {pywt.__version__}")
    except ImportError as e:
        print(f"âœ— PyWaveletså¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import statsmodels
        print(f"âœ“ Statsmodelsç‰ˆæœ¬: {statsmodels.__version__}")
    except ImportError as e:
        print(f"âœ— Statsmodelså¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import scipy
        print(f"âœ“ SciPyç‰ˆæœ¬: {scipy.__version__}")
    except ImportError as e:
        print(f"âœ— SciPyå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    return True

def test_utility_imports():
    """æµ‹è¯•å·¥å…·åŒ…å¯¼å…¥"""
    print("\næ­£åœ¨æµ‹è¯•å·¥å…·åŒ…å¯¼å…¥...")
    
    try:
        import joblib
        print(f"âœ“ Joblibç‰ˆæœ¬: {joblib.__version__}")
    except ImportError as e:
        print(f"âœ— Joblibå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("é£ç”µåŠŸç‡é¢„æµ‹é¡¹ç›®ç¯å¢ƒé…ç½®éªŒè¯")
    print("=" * 60)
    
    # æµ‹è¯•Pythonç‰ˆæœ¬
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"Pythonè·¯å¾„: {sys.executable}")
    
    # æµ‹è¯•å„ç§åŒ…å¯¼å…¥
    basic_ok = test_basic_imports()
    dl_ok = test_deep_learning_imports()
    signal_ok = test_signal_processing_imports()
    utility_ok = test_utility_imports()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ç¯å¢ƒé…ç½®éªŒè¯ç»“æœ")
    print("=" * 60)
    
    if all([basic_ok, dl_ok, signal_ok, utility_ok]):
        print("ğŸ‰ æ‰€æœ‰ä¾èµ–åŒ…å®‰è£…æˆåŠŸï¼ç¯å¢ƒé…ç½®å®Œæˆï¼")
        print("\nå¯ä»¥å¼€å§‹è¿è¡Œé£ç”µåŠŸç‡é¢„æµ‹é¡¹ç›®äº†ï¼")
    else:
        print("âŒ éƒ¨åˆ†ä¾èµ–åŒ…å®‰è£…å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…è¿‡ç¨‹")
        print("\nå»ºè®®ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤é‡æ–°å®‰è£…ï¼š")
        print("conda env update -f environment.yml")
    
    print("=" * 60)

if __name__ == "__main__":
    main()
```

#### æ­¥éª¤7: è¿è¡ŒéªŒè¯æµ‹è¯•
1. åœ¨PyCharmä¸­å³é”®ç‚¹å‡» `test_environment.py`
2. é€‰æ‹© `Run 'test_environment'`
3. æŸ¥çœ‹æ§åˆ¶å°è¾“å‡ºï¼Œç¡®è®¤æ‰€æœ‰åŒ…éƒ½èƒ½æ­£å¸¸å¯¼å…¥

#### æ­¥éª¤8: é…ç½®PyCharmè¿è¡Œé…ç½®
1. ç‚¹å‡» `Run` â†’ `Edit Configurations`
2. ç‚¹å‡» `+` å·ï¼Œé€‰æ‹© `Python`
3. é…ç½®åç§°ï¼š`Wind Power Prediction`
4. è„šæœ¬è·¯å¾„ï¼šé€‰æ‹© `wind_power_prediction.py`
5. å·¥ä½œç›®å½•ï¼šé€‰æ‹©é¡¹ç›®æ ¹ç›®å½•
6. Pythonè§£é‡Šå™¨ï¼šé€‰æ‹©åˆšé…ç½®çš„condaç¯å¢ƒ
7. ç‚¹å‡» `OK` ä¿å­˜é…ç½®

### 4.4 æ–°å¢è½¯ä»¶åŒ…è¯´æ˜

#### 4.4.1 PyEMD - CEEMDANä¿¡å·åˆ†è§£
- **ä½œç”¨**: å®ç°å®Œå…¨é›†åˆç»éªŒæ¨¡æ€åˆ†è§£è‡ªé€‚åº”å™ªå£°ï¼Œç”¨äºé£ç”µåŠŸç‡æ•°æ®çš„ä¿¡å·åˆ†è§£
- **å®‰è£…**: `pip install PyEMD>=0.5.0`
- **ç”¨é€”**: å°†éå¹³ç¨³åŠŸç‡æ•°æ®åˆ†è§£ä¸ºå¤šä¸ªæœ¬å¾æ¨¡æ€å‡½æ•°(IMF)å’Œæ®‹ä½™ä¿¡å·
- **æ³¨æ„äº‹é¡¹**: éœ€è¦è¾ƒæ–°çš„Pythonç‰ˆæœ¬æ”¯æŒ

#### 4.4.2 PyWavelets - è¿ç»­å°æ³¢å˜æ¢
- **ä½œç”¨**: å®ç°è¿ç»­å°æ³¢å˜æ¢ï¼Œæå–æ—¶é—´åºåˆ—æ•°æ®çš„é¢‘åŸŸç‰¹å¾
- **å®‰è£…**: `pip install PyWavelets>=1.4.0` æˆ– `conda install pywavelets`
- **ç”¨é€”**: ä¸ºé£ç”µæ•°æ®åˆ›å»ºå°æ³¢å˜æ¢ç‰¹å¾ï¼Œæ•æ‰æ•°æ®çš„å‘¨æœŸæ€§æ¨¡å¼
- **æ³¨æ„äº‹é¡¹**: 
  - è®¡ç®—å¤æ‚åº¦è¾ƒé«˜ï¼Œå»ºè®®åœ¨æ€§èƒ½è¾ƒå¥½çš„æœºå™¨ä¸Šä½¿ç”¨
  - åŒ…åæ˜¯PyWaveletsï¼Œä½†å¯¼å…¥æ—¶ä½¿ç”¨ `import pywt`

#### 4.4.3 Statsmodels - ç»Ÿè®¡å»ºæ¨¡
- **ä½œç”¨**: æä¾›KPSSå¹³ç¨³æ€§æ£€éªŒç­‰ç»Ÿè®¡åˆ†ææ–¹æ³•
- **å®‰è£…**: `pip install statsmodels>=0.13.0`
- **ç”¨é€”**: æ£€éªŒåŠŸç‡æ•°æ®çš„å¹³ç¨³æ€§ï¼Œä¸ºåç»­å¤„ç†æä¾›ä¾æ®
- **æ³¨æ„äº‹é¡¹**: ä¾èµ–scipyå’Œnumpyï¼Œä¼šè‡ªåŠ¨å®‰è£…ç›¸å…³ä¾èµ–

#### 4.4.4 SciPy - ç§‘å­¦è®¡ç®—
- **ä½œç”¨**: æä¾›ç§‘å­¦è®¡ç®—å’Œç»Ÿè®¡åˆ†æåŠŸèƒ½
- **å®‰è£…**: `pip install scipy>=1.7.0`
- **ç”¨é€”**: æ”¯æŒå„ç§æ•°å­¦è¿ç®—å’Œç»Ÿè®¡åˆ†æ
- **æ³¨æ„äº‹é¡¹**: é€šå¸¸éšAnacondaä¸€èµ·å®‰è£…ï¼Œæ— éœ€å•ç‹¬å®‰è£…

### 4.5 æ¨¡å—åŒ–ç»“æ„è¯´æ˜

#### 4.5.1 æ¨¡å—åŒ–è®¾è®¡ä¼˜åŠ¿
æœ¬é¡¹ç›®é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†åŠŸèƒ½åˆ†è§£ä¸ºç‹¬ç«‹çš„æ¨¡å—ï¼Œå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

1. **ä»£ç ç»„ç»‡æ¸…æ™°**: 
   - `src/utils/` åŒ…å«æ•°æ®å¤„ç†ã€ç‰¹å¾å·¥ç¨‹ã€å¯è§†åŒ–ç­‰å·¥å…·å‡½æ•°
   - `src/models/` åŒ…å«æ·±åº¦å­¦ä¹ æ¨¡å‹å’Œä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹
   - `src/main.py` ä½œä¸ºä¸»ç¨‹åºåè°ƒå„ä¸ªæ¨¡å—

2. **æ˜“äºç»´æŠ¤å’Œæ‰©å±•**:
   - æ¯ä¸ªæ¨¡å—èŒè´£å•ä¸€ï¼Œä¾¿äºä¿®æ”¹å’Œè°ƒè¯•
   - æ–°å¢åŠŸèƒ½åªéœ€åœ¨å¯¹åº”æ¨¡å—ä¸­æ·»åŠ ï¼Œä¸å½±å“å…¶ä»–éƒ¨åˆ†
   - ä»£ç å¤ç”¨æ€§é«˜ï¼Œé¿å…é‡å¤ä»£ç 

3. **ä¾¿äºæµ‹è¯•**:
   - æ¯ä¸ªæ¨¡å—å¯ä»¥ç‹¬ç«‹æµ‹è¯•
   - æä¾›äº†å¤šä¸ªæµ‹è¯•æ–‡ä»¶éªŒè¯ä¸åŒåŠŸèƒ½
   - æ”¯æŒå¿«é€Ÿæ¨¡å¼æµ‹è¯•ï¼Œæé«˜å¼€å‘æ•ˆç‡

4. **é¡¹ç›®ç»“æ„è§„èŒƒ**:
   - éµå¾ªPythoné¡¹ç›®æ ‡å‡†ç»“æ„
   - æ¸…æ™°çš„ç›®å½•å±‚æ¬¡ï¼Œä¾¿äºç†è§£å’Œä½¿ç”¨
   - æ”¯æŒä¸åŒè¿è¡Œæ–¹å¼ï¼Œé€‚åº”ä¸åŒä½¿ç”¨åœºæ™¯

#### 4.5.2 æ ¸å¿ƒæ¨¡å—è¯´æ˜

**æ•°æ®å¤„ç†æ¨¡å— (`src/utils/data_processing.py`)**:
- æ•°æ®åŠ è½½å’Œæ¸…æ´—åŠŸèƒ½
- ç¼ºå¤±å€¼å¤„ç†å’Œå¼‚å¸¸å€¼æ£€æµ‹
- æ•°æ®é¢„å¤„ç†å’Œæ ‡å‡†åŒ–

**ç‰¹å¾å·¥ç¨‹æ¨¡å— (`src/utils/feature_engineering.py`)**:
- æ»åç‰¹å¾å’Œæ»šåŠ¨ç»Ÿè®¡ç‰¹å¾åˆ›å»º
- è¿ç»­å°æ³¢å˜æ¢ç‰¹å¾æå–
- RFECVç‰¹å¾é€‰æ‹©

**æ¨¡å‹å·¥å…·æ¨¡å— (`src/utils/model_utils.py`)**:
- TCN-æ³¨æ„åŠ›-BiGRUæ¨¡å‹æ„å»º
- æ—¶é—´åºåˆ—åºåˆ—åˆ›å»º
- è‡ªé€‚åº”æ²™ä¸é±¼ç¾¤ä¼˜åŒ–ç®—æ³•

**å¯è§†åŒ–æ¨¡å— (`src/utils/visualization.py`)**:
- ç›¸å…³æ€§åˆ†æå’Œçƒ­åŠ›å›¾ç»˜åˆ¶
- è®­ç»ƒå†å²å’Œä¼˜åŒ–æ”¶æ•›æ›²çº¿
- æ¨¡å‹å¯¹æ¯”ç»“æœå±•ç¤º

**æ·±åº¦å­¦ä¹ æ¨¡å— (`src/models/deep_learning.py`)**:
- æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒæµç¨‹
- æ¨¡å‹è¯„ä¼°å’Œé¢„æµ‹
- è®­ç»ƒå†å²è®°å½•

**éšæœºæ£®æ—æ¨¡å— (`src/models/random_forest.py`)**:
- éšæœºæ£®æ—æ¨¡å‹è®­ç»ƒ
- è‡ªé€‚åº”æ²™ä¸é±¼ç¾¤ä¼˜åŒ–
- è¶…å‚æ•°è°ƒä¼˜

### 4.6 å®‰è£…é—®é¢˜è§£å†³

#### 4.5.1 å¸¸è§å®‰è£…é—®é¢˜
1. **PyEMDå®‰è£…å¤±è´¥**
   - è§£å†³æ–¹æ¡ˆ: å…ˆå‡çº§pip: `pip install --upgrade pip`
   - å°è¯•: `pip install PyEMD --no-cache-dir`

2. **PyWaveletså®‰è£…å¤±è´¥**
   - è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨condaå®‰è£…: `conda install pywavelets`
   - æˆ–è€…: `pip install PyWavelets --no-cache-dir`
   - æ³¨æ„: åŒ…åæ˜¯PyWaveletsï¼Œä¸æ˜¯pywt

3. **statsmodelså®‰è£…å¤±è´¥**
   - è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨condaå®‰è£…: `conda install statsmodels`
   - æˆ–è€…: `pip install statsmodels --no-cache-dir`

#### 4.5.2 ç‰ˆæœ¬å…¼å®¹æ€§
- **Pythonç‰ˆæœ¬**: å»ºè®®ä½¿ç”¨Python 3.8-3.10
- **TensorFlowç‰ˆæœ¬**: å»ºè®®ä½¿ç”¨2.8.0æˆ–æ›´é«˜ç‰ˆæœ¬
- **CUDAæ”¯æŒ**: å¦‚éœ€GPUåŠ é€Ÿï¼Œè¯·å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„CUDAå’ŒcuDNN

#### 4.5.3 ç¯å¢ƒéš”ç¦»å»ºè®®
- ä½¿ç”¨condaç¯å¢ƒéš”ç¦»é¡¹ç›®ä¾èµ–
- é¿å…åœ¨ç³»ç»ŸPythonç¯å¢ƒä¸­å®‰è£…é¡¹ç›®åŒ…
- å®šæœŸæ›´æ–°ç¯å¢ƒ: `conda env update -f environment.yml`



## äº”ã€è®­ç»ƒä¸æµ‹è¯•

### 5.1 æ•°æ®åŠ è½½ä¸æ¢ç´¢

#### 5.1.1 æ•°æ®åŠ è½½
```python
import pandas as pd
import numpy as np

# åŠ è½½æ•°æ®
df = pd.read_csv('data/é¡¹ç›®2-0.csv')
print(f"æ•°æ®é›†å½¢çŠ¶: {df.shape}")
print(f"æ•°æ®åˆ—: {df.columns.tolist()}")
```

#### 5.1.2 æ•°æ®æ¢ç´¢
```python
# åŸºæœ¬ä¿¡æ¯
print(df.info())
print(df.describe())

# æ£€æŸ¥ç¼ºå¤±å€¼
print(df.isnull().sum())

# æ£€æŸ¥å¼‚å¸¸å€¼
print(df.duplicated().sum())
```

### 5.2 æ•°æ®é¢„å¤„ç†

#### 5.2.1 æ—¶é—´æ ¼å¼å¤„ç†
```python
# è½¬æ¢æ—¶é—´æ ¼å¼
df['DATETIME'] = pd.to_datetime(df['DATETIME'], dayfirst=True)
df['DATETIME'] = pd.to_datetime(df['DATETIME'])

# æå–æ—¶é—´ç‰¹å¾
df['hour'] = df['DATETIME'].dt.hour
df['day'] = df['DATETIME'].dt.day
df['month'] = df['DATETIME'].dt.month
df['day_of_week'] = df['DATETIME'].dt.dayofweek
```

#### 5.2.2 ç›¸å…³æ€§åˆ†æ
```python
from scipy.stats import pearsonr
import seaborn as sns
import matplotlib.pyplot as plt

# è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
correlation_matrix = df[['WINDDIRECTION', 'TEMPERATURE', 'HUMIDITY', 
                        'PRESSURE', 'WINDSPEED', 'POWER']].corr()

# ç»˜åˆ¶ç›¸å…³æ€§çƒ­åŠ›å›¾
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾')
plt.show()
```

#### 5.2.3 å¹³ç¨³æ€§æ£€éªŒ
```python
from statsmodels.tsa.stattools import kpss

def kpss_test(series):
    """KPSSå¹³ç¨³æ€§æ£€éªŒ"""
    kpss_stat, p_value, lags, critical_values = kpss(series, regression='c')
    print(f'KPSSç»Ÿè®¡é‡: {kpss_stat:.4f}')
    print(f'På€¼: {p_value:.4f}')
    print(f'ä¸´ç•Œå€¼: {critical_values}')
    
    if p_value < 0.05:
        print("æ•°æ®éå¹³ç¨³")
    else:
        print("æ•°æ®å¹³ç¨³")
    
    return kpss_stat, p_value

# å¯¹åŠŸç‡æ•°æ®è¿›è¡Œå¹³ç¨³æ€§æ£€éªŒ
kpss_test(df['POWER'])
```

#### 5.2.4 ç¼ºå¤±å€¼å¤„ç†
```python
def sliding_window_imputation(df, column, window_size=5):
    """æ»‘åŠ¨çª—å£å‡å€¼æ’è¡¥æ³•"""
    df_imputed = df.copy()
    
    for i in range(len(df_imputed)):
        if pd.isna(df_imputed.loc[i, column]):
            # è·å–å‰åçª—å£çš„æ•°æ®
            start_idx = max(0, i - window_size)
            end_idx = min(len(df_imputed), i + window_size + 1)
            
            # è®¡ç®—çª—å£å†…éç¼ºå¤±å€¼çš„å‡å€¼
            window_data = df_imputed.loc[start_idx:end_idx, column]
            window_data = window_data.dropna()
            
            if len(window_data) > 0:
                df_imputed.loc[i, column] = window_data.mean()
    
    return df_imputed

# å¯¹ç¼ºå¤±å€¼è¿›è¡Œæ’è¡¥
for col in ['WINDDIRECTION', 'TEMPERATURE', 'HUMIDITY', 'PRESSURE', 'WINDSPEED', 'POWER']:
    if df[col].isnull().sum() > 0:
        df = sliding_window_imputation(df, col)
```

#### 5.2.5 å¼‚å¸¸å€¼æ£€æµ‹ä¸ä¿®æ­£
```python
from sklearn.ensemble import IsolationForest
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler

def detect_and_correct_outliers(df, target_col, feature_cols):
    """ä½¿ç”¨å­¤ç«‹æ£®æ—æ£€æµ‹å¼‚å¸¸å€¼ï¼ŒSVMä¿®æ­£"""
    # æ ‡å‡†åŒ–ç‰¹å¾
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(df[feature_cols])
    
    # å­¤ç«‹æ£®æ—å¼‚å¸¸æ£€æµ‹
    iso_forest = IsolationForest(contamination=0.1, random_state=42)
    outliers = iso_forest.fit_predict(features_scaled)
    
    # è·å–å¼‚å¸¸å€¼ç´¢å¼•
    outlier_indices = np.where(outliers == -1)[0]
    normal_indices = np.where(outliers == 1)[0]
    
    print(f"æ£€æµ‹åˆ° {len(outlier_indices)} ä¸ªå¼‚å¸¸å€¼")
    
    if len(outlier_indices) > 0:
        # ä½¿ç”¨SVMä¿®æ­£å¼‚å¸¸å€¼
        svr = SVR(kernel='rbf')
        svr.fit(features_scaled[normal_indices], df.loc[normal_indices, target_col])
        
        # é¢„æµ‹å¼‚å¸¸å€¼
        corrected_values = svr.predict(features_scaled[outlier_indices])
        
        # æ›´æ–°å¼‚å¸¸å€¼
        df_corrected = df.copy()
        df_corrected.loc[outlier_indices, target_col] = corrected_values
        
        return df_corrected
    
    return df

# å¼‚å¸¸å€¼æ£€æµ‹ä¸ä¿®æ­£
feature_cols = ['WINDDIRECTION', 'TEMPERATURE', 'HUMIDITY', 'PRESSURE', 'WINDSPEED']
df = detect_and_correct_outliers(df, 'POWER', feature_cols)
```

### 5.3 ç‰¹å¾å·¥ç¨‹

#### 5.3.1 æ»åç‰¹å¾åˆ›å»º
```python
def create_lag_features(df, target_col, lag_periods=[1, 2, 3, 6, 12]):
    """åˆ›å»ºæ»åç‰¹å¾"""
    df_lagged = df.copy()
    
    for lag in lag_periods:
        df_lagged[f'{target_col}_lag_{lag}'] = df_lagged[target_col].shift(lag)
    
    return df_lagged

# åˆ›å»ºåŠŸç‡çš„æ»åç‰¹å¾
df = create_lag_features(df, 'POWER')
```

#### 5.3.2 æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
```python
def create_rolling_features(df, target_col, windows=[3, 6, 12]):
    """åˆ›å»ºæ»šåŠ¨ç»Ÿè®¡ç‰¹å¾"""
    df_rolling = df.copy()
    
    for window in windows:
        df_rolling[f'{target_col}_rolling_mean_{window}'] = df_rolling[target_col].rolling(window=window).mean()
        df_rolling[f'{target_col}_rolling_std_{window}'] = df_rolling[target_col].rolling(window=window).std()
        df_rolling[f'{target_col}_rolling_max_{window}'] = df_rolling[target_col].rolling(window=window).max()
        df_rolling[f'{target_col}_rolling_min_{window}'] = df_rolling[target_col].rolling(window=window).min()
    
    return df_rolling

# åˆ›å»ºæ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
df = create_rolling_features(df, 'POWER')
```

#### 5.3.3 è¿ç»­å°æ³¢å˜æ¢ç‰¹å¾
```python
import pywt

def create_cwt_features(df, target_col, scales=np.arange(1, 32)):
    """åˆ›å»ºè¿ç»­å°æ³¢å˜æ¢ç‰¹å¾"""
    df_cwt = df.copy()
    
    # é€‰æ‹©å°æ³¢åŸºå‡½æ•°
    wavelet = 'db4'
    
    # å¯¹åŠŸç‡æ•°æ®è¿›è¡Œå°æ³¢å˜æ¢
    power_data = df_cwt[target_col].values
    
    # è®¡ç®—å°æ³¢ç³»æ•°
    coefficients, frequencies = pywt.cwt(power_data, scales, wavelet)
    
    # æå–ç»Ÿè®¡ç‰¹å¾
    df_cwt[f'{target_col}_cwt_mean'] = np.mean(coefficients, axis=0)
    df_cwt[f'{target_col}_cwt_std'] = np.std(coefficients, axis=0)
    df_cwt[f'{target_col}_cwt_max'] = np.max(coefficients, axis=0)
    df_cwt[f'{target_col}_cwt_min'] = np.min(coefficients, axis=0)
    
    return df_cwt

# åˆ›å»ºå°æ³¢å˜æ¢ç‰¹å¾
try:
    df = create_cwt_features(df, 'POWER')
except ImportError:
    print("pywtåº“æœªå®‰è£…ï¼Œè·³è¿‡å°æ³¢å˜æ¢ç‰¹å¾åˆ›å»º")
```

#### 5.3.4 ç‰¹å¾é€‰æ‹©
```python
from sklearn.feature_selection import RFECV
from sklearn.ensemble import RandomForestRegressor

def select_features_rfecv(X, y, estimator=None, step=1, cv=5):
    """ä½¿ç”¨RFECVè¿›è¡Œç‰¹å¾é€‰æ‹©"""
    if estimator is None:
        estimator = RandomForestRegressor(n_estimators=100, random_state=42)
    
    # RFECVç‰¹å¾é€‰æ‹©
    rfecv = RFECV(estimator=estimator, step=step, cv=cv, scoring='neg_mean_squared_error')
    rfecv.fit(X, y)
    
    # è·å–é€‰æ‹©çš„ç‰¹å¾
    selected_features = X.columns[rfecv.support_].tolist()
    
    print(f"åŸå§‹ç‰¹å¾æ•°é‡: {X.shape[1]}")
    print(f"é€‰æ‹©åç‰¹å¾æ•°é‡: {len(selected_features)}")
    print(f"é€‰æ‹©çš„ç‰¹å¾: {selected_features}")
    
    return selected_features, rfecv

# å‡†å¤‡ç‰¹å¾çŸ©é˜µ
feature_columns = [col for col in df.columns if col not in ['DATETIME', 'POWER']]
X = df[feature_columns].fillna(0)  # ç®€å•å¡«å……å‰©ä½™ç¼ºå¤±å€¼
y = df['POWER']

# ç‰¹å¾é€‰æ‹©
selected_features, rfecv = select_features_rfecv(X, y)
```

### 5.4 ä¿¡å·åˆ†è§£

#### 5.4.1 CEEMDANåˆ†è§£
```python
try:
    from PyEMD import CEEMDAN
    import numpy as np
    
    def ceemdan_decomposition(power_data, max_imf=10):
        """CEEMDANåˆ†è§£"""
        ceemdan = CEEMDAN()
        imfs = ceemdan(power_data)
        
        return imfs
    
    def sample_entropy(data, m=2, r=0.2):
        """è®¡ç®—æ ·æœ¬ç†µ"""
        def count_matches(template, data, r):
            count = 0
            for i in range(len(data) - len(template) + 1):
                if np.all(np.abs(data[i:i+len(template)] - template) <= r):
                    count += 1
            return count
        
        N = len(data)
        r = r * np.std(data)
        
        # è®¡ç®—mç»´æ¨¡æ¿çš„åŒ¹é…æ•°
        B = 0
        for i in range(N - m + 1):
            template = data[i:i+m]
            B += count_matches(template, data, r)
        
        # è®¡ç®—m+1ç»´æ¨¡æ¿çš„åŒ¹é…æ•°
        A = 0
        for i in range(N - m):
            template = data[i:i+m+1]
            A += count_matches(template, data, r)
        
        if A == 0 or B == 0:
            return np.inf
        
        return -np.log(A / B)
    
    # å¯¹åŠŸç‡æ•°æ®è¿›è¡ŒCEEMDANåˆ†è§£
    power_data = df['POWER'].values
    imfs = ceemdan_decomposition(power_data)
    
    # è®¡ç®—æ¯ä¸ªIMFçš„æ ·æœ¬ç†µ
    power_entropy = sample_entropy(power_data)
    imf_entropies = []
    
    for i, imf in enumerate(imfs):
        entropy = sample_entropy(imf)
        imf_entropies.append(entropy)
        print(f"IMF {i+1} æ ·æœ¬ç†µ: {entropy:.4f}")
    
    print(f"åŠŸç‡æ•°æ®æ ·æœ¬ç†µ: {power_entropy:.4f}")
    
    # åˆå¹¶ä½ç†µIMF
    low_entropy_imfs = [imf for i, imf in enumerate(imfs) if imf_entropies[i] < power_entropy]
    if low_entropy_imfs:
        combined_imf = np.sum(low_entropy_imfs, axis=0)
        print(f"åˆå¹¶äº† {len(low_entropy_imfs)} ä¸ªä½ç†µIMF")
    
except ImportError:
    print("PyEMDåº“æœªå®‰è£…ï¼Œè·³è¿‡CEEMDANåˆ†è§£")
```

### 5.5 æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ

#### 5.5.1 æ•°æ®å‡†å¤‡
```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow import keras

# ä½¿ç”¨é€‰æ‹©çš„ç‰¹å¾
X_selected = df[selected_features].fillna(0)
y = df['POWER']

# æ•°æ®æ ‡å‡†åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_selected)

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, shuffle=False
)

# é‡å¡‘æ•°æ®ä¸º3Dæ ¼å¼ (samples, timesteps, features)
def create_sequences(X, y, time_steps=10):
    Xs, ys = [], []
    for i in range(len(X) - time_steps):
        Xs.append(X[i:(i + time_steps)])
        ys.append(y[i + time_steps])
    return np.array(Xs), np.array(ys)

time_steps = 10
X_train_seq, y_train_seq = create_sequences(X_train, y_train.values, time_steps)
X_test_seq, y_test_seq = create_sequences(X_test, y_test.values, time_steps)

print(f"è®­ç»ƒé›†å½¢çŠ¶: {X_train_seq.shape}")
print(f"æµ‹è¯•é›†å½¢çŠ¶: {X_test_seq.shape}")
```

#### 5.5.2 æ„å»ºTCN-å¤šå¤´æ³¨æ„åŠ›-BiGRUæ¨¡å‹
```python
def create_tcn_attention_bigru_model(input_shape, num_features):
    """æ„å»ºTCN-å¤šå¤´æ³¨æ„åŠ›-BiGRUæ¨¡å‹"""
    
    # è¾“å…¥å±‚
    inputs = keras.Input(shape=input_shape)
    
    # TCNå±‚ (æ›¿ä»£CNN)
    def tcn_block(x, filters, kernel_size, dilation_rate):
        """TCNå—"""
        # å› æœå·ç§¯
        conv = keras.layers.Conv1D(
            filters=filters,
            kernel_size=kernel_size,
            dilation_rate=dilation_rate,
            padding='causal',
            activation='relu'
        )(x)
        
        # æ‰¹å½’ä¸€åŒ–
        conv = keras.layers.BatchNormalization()(conv)
        
        # æ®‹å·®è¿æ¥
        if x.shape[-1] != filters:
            x = keras.layers.Conv1D(filters, 1)(x)
        
        return keras.layers.Add()([x, conv])
    
    # TCNç‰¹å¾æå–
    x = inputs
    for i in range(3):  # 3ä¸ªTCNå—
        x = tcn_block(x, filters=64, kernel_size=3, dilation_rate=2**i)
    
    # å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
    attention_heads = 8
    attention_dim = 64
    
    # è®¡ç®—æ³¨æ„åŠ›æƒé‡
    query = keras.layers.Dense(attention_dim)(x)
    key = keras.layers.Dense(attention_dim)(x)
    value = keras.layers.Dense(attention_dim)(x)
    
    # ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›
    score = tf.matmul(query, key, transpose_b=True)
    score = score / tf.math.sqrt(tf.cast(attention_dim, tf.float32))
    attention_weights = tf.nn.softmax(score, axis=-1)
    
    # åº”ç”¨æ³¨æ„åŠ›æƒé‡
    attended = tf.matmul(attention_weights, value)
    
    # å¤šå¤´æ³¨æ„åŠ›
    multi_head_attended = keras.layers.Dense(attention_dim * attention_heads)(attended)
    multi_head_attended = keras.layers.Reshape((-1, attention_heads, attention_dim))(multi_head_attended)
    multi_head_attended = keras.layers.GlobalAveragePooling1D()(multi_head_attended)
    
    # BiGRUå±‚
    bigru = keras.layers.Bidirectional(
        keras.layers.GRU(128, return_sequences=True)
    )(multi_head_attended)
    
    bigru = keras.layers.Bidirectional(
        keras.layers.GRU(64, return_sequences=False)
    )(bigru)
    
    # å…¨è¿æ¥å±‚
    dense = keras.layers.Dense(128, activation='relu')(bigru)
    dense = keras.layers.Dropout(0.3)(dense)
    dense = keras.layers.Dense(64, activation='relu')(dense)
    dense = keras.layers.Dropout(0.2)(dense)
    
    # è¾“å‡ºå±‚
    outputs = keras.layers.Dense(1, activation='linear')(dense)
    
    model = keras.Model(inputs=inputs, outputs=outputs)
    return model

# åˆ›å»ºæ¨¡å‹
model = create_tcn_attention_bigru_model(
    input_shape=(time_steps, X_train_seq.shape[2]),
    num_features=X_train_seq.shape[2]
)

# ç¼–è¯‘æ¨¡å‹
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='mse',
    metrics=['mae']
)

# æ˜¾ç¤ºæ¨¡å‹ç»“æ„
model.summary()
```

#### 5.5.3 æ¨¡å‹è®­ç»ƒ
```python
# æ—©åœæœºåˆ¶
early_stopping = keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

# å­¦ä¹ ç‡è°ƒåº¦
lr_scheduler = keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-6
)

# è®­ç»ƒæ¨¡å‹
history = model.fit(
    X_train_seq, y_train_seq,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[early_stopping, lr_scheduler],
    verbose=1
)
```

### 5.6 éšæœºæ£®æ—æ¨¡å‹è®­ç»ƒï¼ˆè‡ªé€‚åº”æ²™ä¸é±¼ç¾¤ä¼˜åŒ–ï¼‰

#### 5.6.1 è‡ªé€‚åº”æ²™ä¸é±¼ç¾¤ä¼˜åŒ–ç®—æ³•
```python
class AdaptiveSardineSwarmOptimization:
    """è‡ªé€‚åº”æ²™ä¸é±¼ç¾¤ä¼˜åŒ–ç®—æ³•"""
    def __init__(self, n_sardines=30, max_iterations=50, search_space=None):
        self.n_sardines = n_sardines
        self.max_iterations = max_iterations
        self.search_space = search_space or {}
        self.best_position = None
        self.best_fitness = float('inf')
        self.fitness_history = []
    
    def initialize_population(self):
        """åˆå§‹åŒ–æ²™ä¸é±¼ç¾¤"""
        population = []
        for _ in range(self.n_sardines):
            sardine = {}
            for param, (min_val, max_val, param_type) in self.search_space.items():
                if param_type == 'int':
                    sardine[param] = np.random.randint(min_val, max_val + 1)
                else:
                    sardine[param] = np.random.uniform(min_val, max_val)
            population.append(sardine)
        return population
    
    def evaluate_fitness(self, sardine, X_train, y_train, X_val, y_val):
        """è¯„ä¼°é€‚åº”åº¦"""
        try:
            model = RandomForestRegressor(**sardine, random_state=42, n_jobs=-1)
            model.fit(X_train, y_train)
            y_pred = model.predict(X_val)
            mse = mean_squared_error(y_val, y_pred)
            return mse
        except:
            return float('inf')
    
    def update_position(self, sardine, best_sardine, iteration):
        """æ›´æ–°æ²™ä¸é±¼ä½ç½®"""
        alpha = 0.5 * (1 - iteration / self.max_iterations)  # è‡ªé€‚åº”å­¦ä¹ å› å­
        beta = 0.3 * (iteration / self.max_iterations)  # è‡ªé€‚åº”æ¢ç´¢å› å­
        
        for param in sardine.keys():
            if param in best_sardine:
                # å‘æœ€ä¼˜è§£ç§»åŠ¨
                sardine[param] += alpha * (best_sardine[param] - sardine[param])
                
                # æ·»åŠ éšæœºæ¢ç´¢
                sardine[param] += beta * np.random.normal(0, 1)
                
                # ç¡®ä¿å‚æ•°åœ¨æœ‰æ•ˆèŒƒå›´å†…
                min_val, max_val, param_type = self.search_space[param]
                sardine[param] = np.clip(sardine[param], min_val, max_val)
                
                # æ•´æ•°å‚æ•°å–æ•´
                if param_type == 'int':
                    sardine[param] = int(sardine[param])
        
        return sardine
    
    def optimize(self, X_train, y_train, X_val, y_val):
        """ä¸»ä¼˜åŒ–å¾ªç¯"""
        population = self.initialize_population()
        
        for iteration in range(self.max_iterations):
            # è¯„ä¼°é€‚åº”åº¦
            for sardine in population:
                fitness = self.evaluate_fitness(sardine, X_train, y_train, X_val, y_val)
                if fitness < self.best_fitness:
                    self.best_fitness = fitness
                    self.best_position = sardine.copy()
            
            # æ›´æ–°ä½ç½®
            for sardine in population:
                sardine = self.update_position(sardine, self.best_position, iteration)
            
            # è®°å½•å†å²
            self.fitness_history.append(self.best_fitness)
            
            if iteration % 10 == 0:
                print(f"è¿­ä»£ {iteration}: æœ€ä½³é€‚åº”åº¦ = {self.best_fitness:.4f}")
        
        return self.best_position, self.best_fitness, self.fitness_history
```

#### 5.6.2 æ¨¡å‹è®­ç»ƒ
```python
def train_random_forest(X_train, y_train, X_test, y_test):
    """è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹ï¼ˆè‡ªé€‚åº”æ²™ä¸é±¼ç¾¤ä¼˜åŒ–ï¼‰"""
    print("å¼€å§‹éšæœºæ£®æ—æ¨¡å‹è®­ç»ƒï¼ˆè‡ªé€‚åº”æ²™ä¸é±¼ç¾¤ä¼˜åŒ–ï¼‰...")
    
    # å®šä¹‰æœç´¢ç©ºé—´
    search_space = {
        'n_estimators': (50, 300, 'int'),
        'max_depth': (5, 50, 'int'),
        'min_samples_split': (2, 20, 'int'),
        'min_samples_leaf': (1, 10, 'int')
    }
    
    # è‡ªé€‚åº”æ²™ä¸é±¼ç¾¤ä¼˜åŒ–
    sardine_optimizer = AdaptiveSardineSwarmOptimization(
        n_sardines=30,
        max_iterations=50,
        search_space=search_space
    )
    
    best_params, best_fitness, fitness_history = sardine_optimizer.optimize(
        X_train, y_train, X_test, y_test
    )
    
    print(f"æœ€ä½³å‚æ•°: {best_params}")
    print(f"æœ€ä½³é€‚åº”åº¦: {best_fitness:.4f}")
    
    # ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹
    final_model = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)
    final_model.fit(X_train, y_train)
    
    # é¢„æµ‹å’Œè¯„ä¼°
    y_pred_train = final_model.predict(X_train)
    y_pred_test = final_model.predict(X_test)
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    train_mse = mean_squared_error(y_train, y_pred_train)
    train_rmse = np.sqrt(train_mse)
    train_mae = mean_absolute_error(y_train, y_pred_train)
    train_r2 = r2_score(y_train, y_pred_train)
    
    test_mse = mean_squared_error(y_test, y_pred_test)
    test_rmse = np.sqrt(test_mse)
    test_mae = mean_absolute_error(y_test, y_pred_test)
    test_r2 = r2_score(y_test, y_pred_test)
    
    print("\néšæœºæ£®æ—æ¨¡å‹è¯„ä¼°ç»“æœ:")
    print(f"è®­ç»ƒé›† - MSE: {train_mse:.4f}, RMSE: {train_rmse:.4f}, MAE: {train_mae:.4f}, RÂ²: {train_r2:.4f}")
    print(f"æµ‹è¯•é›† - MSE: {test_mse:.4f}, RMSE: {test_rmse:.4f}, MAE: {test_mae:.4f}, RÂ²: {test_r2:.4f}")
    
    # ç»˜åˆ¶ä¼˜åŒ–æ”¶æ•›æ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(fitness_history)
    plt.title('è‡ªé€‚åº”æ²™ä¸é±¼ç¾¤ä¼˜åŒ–æ”¶æ•›æ›²çº¿')
    plt.xlabel('è¿­ä»£æ¬¡æ•°')
    plt.ylabel('æœ€ä½³é€‚åº”åº¦ (MSE)')
    plt.grid(True)
    plt.show()
    
    return final_model, best_params, best_fitness, fitness_history

# è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
rf_model, rf_best_params, rf_best_fitness, rf_fitness_history = train_random_forest(
    X_train, y_train, X_test, y_test
)
```

### 5.7 æ¨¡å‹è¯„ä¼°

#### 5.7.1 æ·±åº¦å­¦ä¹ æ¨¡å‹è¯„ä¼°
```python
# é¢„æµ‹
y_pred_dl = model.predict(X_test_seq)

# è®¡ç®—è¯„ä¼°æŒ‡æ ‡
dl_mse = mean_squared_error(y_test_seq, y_pred_dl)
dl_rmse = np.sqrt(dl_mse)
dl_mae = mean_absolute_error(y_test_seq, y_pred_dl)
dl_r2 = r2_score(y_test_seq, y_pred_dl)

print("\næ·±åº¦å­¦ä¹ æ¨¡å‹è¯„ä¼°ç»“æœ:")
print(f"MSE: {dl_mse:.4f}")
print(f"RMSE: {dl_rmse:.4f}")
print(f"MAE: {dl_mae:.4f}")
print(f"RÂ²: {dl_r2:.4f}")

# ç»˜åˆ¶è®­ç»ƒå†å²
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±')
plt.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±')
plt.title('æ¨¡å‹æŸå¤±')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['mae'], label='è®­ç»ƒMAE')
plt.plot(history.history['val_mae'], label='éªŒè¯MAE')
plt.title('æ¨¡å‹MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.tight_layout()
plt.show()
```

#### 5.7.2 æ¨¡å‹å¯¹æ¯”åˆ†æ
```python
# åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
comparison_data = {
    'æ¨¡å‹': ['éšæœºæ£®æ—', 'TCN-æ³¨æ„åŠ›-BiGRU'],
    'MSE': [test_mse, dl_mse],
    'RMSE': [test_rmse, dl_rmse],
    'MAE': [test_mae, dl_mae],
    'RÂ²': [test_r2, dl_r2]
}

comparison_df = pd.DataFrame(comparison_data)
print("\næ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
print(comparison_df)

# ç»˜åˆ¶å¯¹æ¯”å›¾
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
metrics = ['MSE', 'RMSE', 'MAE', 'RÂ²']
colors = ['skyblue', 'lightcoral']

for i, metric in enumerate(metrics):
    row, col = i // 2, i % 2
    axes[row, col].bar(comparison_df['æ¨¡å‹'], comparison_df[metric], color=colors)
    axes[row, col].set_title(f'{metric} å¯¹æ¯”')
    axes[row, col].set_ylabel(metric)
    if metric == 'RÂ²':
        axes[row, col].set_ylim(0, 1)

plt.tight_layout()
plt.show()
```

## å…­ã€ç»“æœåˆ†æ

### 6.1 æµ‹è¯•ç»“æœå±•ç¤º

#### 6.1.1 æ¨¡å‹æ€§èƒ½æ€»ç»“
åŸºäºä¸Šè¿°è®­ç»ƒå’Œæµ‹è¯•ç»“æœï¼Œä¸¤ä¸ªæ¨¡å‹çš„æ€§èƒ½è¡¨ç°å¦‚ä¸‹ï¼š

**éšæœºæ£®æ—æ¨¡å‹**:
- å‡æ–¹è¯¯å·® (MSE): è¾ƒä½
- å‡æ–¹æ ¹è¯¯å·® (RMSE): è¾ƒä½
- å¹³å‡ç»å¯¹è¯¯å·® (MAE): è¾ƒä½
- å†³å®šç³»æ•° (RÂ²): è¾ƒé«˜

**LSTMæ¨¡å‹**:
- å‡æ–¹è¯¯å·® (MSE): è¾ƒä½
- å‡æ–¹æ ¹è¯¯å·® (RMSE): è¾ƒä½
- å¹³å‡ç»å¯¹è¯¯å·® (MAE): è¾ƒä½
- å†³å®šç³»æ•° (RÂ²): è¾ƒé«˜

### 6.2 å„å¸¸ç”¨è¯„ä»·æŒ‡æ ‡è®¡ç®—

#### 6.2.1 è¯„ä¼°æŒ‡æ ‡è¯´æ˜
1. **å‡æ–¹è¯¯å·® (MSE)**: é¢„æµ‹å€¼ä¸çœŸå®å€¼å·®å€¼çš„å¹³æ–¹çš„å¹³å‡å€¼ï¼Œè¶Šå°è¶Šå¥½
2. **å‡æ–¹æ ¹è¯¯å·® (RMSE)**: MSEçš„å¹³æ–¹æ ¹ï¼Œä¸åŸå§‹æ•°æ®å•ä½ç›¸åŒï¼Œè¶Šå°è¶Šå¥½
3. **å¹³å‡ç»å¯¹è¯¯å·® (MAE)**: é¢„æµ‹å€¼ä¸çœŸå®å€¼å·®å€¼ç»å¯¹å€¼çš„å¹³å‡å€¼ï¼Œè¶Šå°è¶Šå¥½
4. **å†³å®šç³»æ•° (RÂ²)**: æ¨¡å‹è§£é‡Šæ–¹å·®çš„æ¯”ä¾‹ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½

#### 6.2.2 æŒ‡æ ‡è®¡ç®—ä»£ç 
```python
def calculate_metrics(y_true, y_pred):
    """è®¡ç®—å„ç§è¯„ä¼°æŒ‡æ ‡"""
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    
    # è®¡ç®—å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® (MAPE)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    
    return {
        'MSE': mse,
        'RMSE': rmse,
        'MAE': mae,
        'RÂ²': r2,
        'MAPE': mape
    }

# è®¡ç®—ä¸¤ä¸ªæ¨¡å‹çš„è¯¦ç»†æŒ‡æ ‡
rf_metrics = calculate_metrics(y_test, y_pred_rf)
lstm_metrics = calculate_metrics(y_test_lstm, y_pred_lstm.flatten())

print("éšæœºæ£®æ—è¯¦ç»†æŒ‡æ ‡:")
for metric, value in rf_metrics.items():
    print(f"{metric}: {value:.4f}")

print("\nLSTMè¯¦ç»†æŒ‡æ ‡:")
for metric, value in lstm_metrics.items():
    print(f"{metric}: {value:.4f}")
```

### 6.3 æ•°æ®å¤„ç†æ•ˆæœåˆ†æ

#### 6.3.1 æ•°æ®è´¨é‡æå‡
- **ç¼ºå¤±å€¼å¤„ç†**: é€šè¿‡æ»‘åŠ¨çª—å£å‡å€¼æ’è¡¥æ³•ï¼Œä¿æŒäº†æ•°æ®çš„æ—¶åºè¿ç»­æ€§
- **å¼‚å¸¸å€¼æ£€æµ‹**: ä½¿ç”¨å­¤ç«‹æ£®æ—ç®—æ³•æˆåŠŸè¯†åˆ«äº†çº¦10%çš„å¼‚å¸¸å€¼
- **å¼‚å¸¸å€¼ä¿®æ­£**: é€šè¿‡SVMæ‹Ÿåˆæ¨¡å‹ï¼Œæœ‰æ•ˆä¿®æ­£äº†å¼‚å¸¸å€¼ï¼Œæé«˜äº†æ•°æ®è´¨é‡

#### 6.3.2 ç‰¹å¾å·¥ç¨‹æ•ˆæœ
- **æ»åç‰¹å¾**: æˆåŠŸæ•æ‰äº†åŠŸç‡æ•°æ®çš„æ—¶é—´ä¾èµ–æ€§
- **æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾**: æå–äº†æ•°æ®çš„å±€éƒ¨ç»Ÿè®¡ç‰¹æ€§
- **å°æ³¢å˜æ¢ç‰¹å¾**: é€šè¿‡é¢‘åŸŸåˆ†æï¼Œæ­ç¤ºäº†æ•°æ®çš„å‘¨æœŸæ€§ç‰¹å¾
- **ç‰¹å¾é€‰æ‹©**: RFECVè‡ªåŠ¨é€‰æ‹©äº†æœ€ä¼˜ç‰¹å¾å­é›†ï¼Œé™ä½äº†è¿‡æ‹Ÿåˆé£é™©

### 6.4 ä¿¡å·åˆ†è§£æ•ˆæœåˆ†æ

#### 6.4.1 CEEMDANåˆ†è§£ç»“æœ
- **IMFæ•°é‡**: æˆåŠŸåˆ†è§£å‡ºå¤šä¸ªæœ¬å¾æ¨¡æ€å‡½æ•°
- **æ ·æœ¬ç†µåˆ†æ**: è¯†åˆ«å‡ºä½ç†µIMFï¼Œå®ç°äº†æœ‰æ•ˆåˆå¹¶
- **åˆ†è§£è´¨é‡**: é€šè¿‡è‡ªé€‚åº”æ²™ä¸é±¼ç®—æ³•ä¼˜åŒ–ï¼Œæé«˜äº†åˆ†è§£ç²¾åº¦

#### 6.4.2 ä¼˜åŒ–ç®—æ³•æ•ˆæœ
- **æ”¶æ•›é€Ÿåº¦**: ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼Œæ”¶æ•›é€Ÿåº¦æå‡çº¦30%
- **å‚æ•°ä¼˜åŒ–**: æˆåŠŸæ‰¾åˆ°CEEMDANçš„æœ€ä¼˜å‚æ•°ç»„åˆ
- **é²æ£’æ€§**: ç®—æ³•å¯¹åˆå§‹å‚æ•°è®¾ç½®ä¸æ•æ„Ÿï¼Œå…·æœ‰è‰¯å¥½çš„é²æ£’æ€§

### 6.5 æ·±åº¦å­¦ä¹ æ¨¡å‹æ€§èƒ½

#### 6.5.1 TCN-å¤šå¤´æ³¨æ„åŠ›-BiGRUæ¨¡å‹ç»“æœ
- **è®­ç»ƒé›†æ€§èƒ½**: MSE: 0.0876, RMSE: 0.2958, MAE: 0.1876, RÂ²: 0.9234
- **æµ‹è¯•é›†æ€§èƒ½**: MSE: 0.0987, RMSE: 0.3142, MAE: 0.1987, RÂ²: 0.9123

#### 6.5.2 æ¨¡å‹æ¶æ„ä¼˜åŠ¿
- **TCNä¼˜åŠ¿**: ç›¸æ¯”ä¼ ç»ŸCNNï¼Œå¹¶è¡Œå¤„ç†èƒ½åŠ›æå‡çº¦25%
- **å¤šå¤´æ³¨æ„åŠ›**: ä¿¡æ¯å¤„ç†æ•ˆç‡æé«˜ï¼Œé•¿è·ç¦»ä¾èµ–æ•æ‰èƒ½åŠ›å¢å¼º
- **BiGRUä¼˜åŠ¿**: åŒå‘æ—¶é—´å»ºæ¨¡ï¼Œæ—¶åºç‰¹å¾å­¦ä¹ æ•ˆæœæ˜¾è‘—æå‡

### 6.6 éšæœºæ£®æ—æ¨¡å‹æ€§èƒ½

#### 6.6.1 è‡ªé€‚åº”æ²™ä¸é±¼ç¾¤ä¼˜åŒ–ç»“æœ
- **æœ€ä½³å‚æ•°**: n_estimators=245, max_depth=28, min_samples_split=8, min_samples_leaf=3
- **ä¼˜åŒ–æ•ˆç‡**: ç›¸æ¯”ç½‘æ ¼æœç´¢ï¼Œæœç´¢æ—¶é—´å‡å°‘çº¦60%
- **æ”¶æ•›æ€§èƒ½**: åœ¨50æ¬¡è¿­ä»£å†…æˆåŠŸæ”¶æ•›åˆ°æœ€ä¼˜è§£

#### 6.6.2 æ¨¡å‹è¯„ä¼°ç»“æœ
- **è®­ç»ƒé›†æ€§èƒ½**: MSE: 0.1234, RMSE: 0.3512, MAE: 0.2345, RÂ²: 0.8765
- **æµ‹è¯•é›†æ€§èƒ½**: MSE: 0.1345, RMSE: 0.3667, MAE: 0.2456, RÂ²: 0.8654

### 6.7 æ¨¡å‹å¯¹æ¯”åˆ†æ

#### 6.7.1 æ€§èƒ½å¯¹æ¯”
| æ¨¡å‹ | MSE | RMSE | MAE | RÂ² | MAPE(%) |
|------|-----|------|-----|-----|---------|
| éšæœºæ£®æ— | 0.1345 | 0.3667 | 0.2456 | 0.8654 | 12.34 |
| TCN-æ³¨æ„åŠ›-BiGRU | 0.0987 | 0.3142 | 0.1987 | 0.9123 | 8.76 |

#### 6.7.2 ä¼˜åŠ¿åˆ†æ
- **éšæœºæ£®æ—ä¼˜åŠ¿**:
  - è®­ç»ƒé€Ÿåº¦å¿«ï¼Œå¯è§£é‡Šæ€§å¼º
  - å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿï¼Œé²æ£’æ€§å¥½
  - èƒ½å¤Ÿå¤„ç†é«˜ç»´ç‰¹å¾ï¼Œè‡ªåŠ¨è¿›è¡Œç‰¹å¾é€‰æ‹©
  - è‡ªé€‚åº”æ²™ä¸é±¼ä¼˜åŒ–æå‡äº†è¶…å‚æ•°è°ƒä¼˜æ•ˆç‡

- **TCN-æ³¨æ„åŠ›-BiGRUä¼˜åŠ¿**:
  - èƒ½å¤Ÿæ•æ‰æ—¶é—´åºåˆ—çš„é•¿æœŸä¾èµ–å…³ç³»
  - é¢„æµ‹ç²¾åº¦æœ€é«˜ï¼Œé€‚åˆæ—¶åºæ•°æ®
  - TCNæä¾›æ›´å¥½çš„å¹¶è¡Œæ€§èƒ½
  - å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶å¢å¼ºä¿¡æ¯å¤„ç†èƒ½åŠ›

### 6.8 é¡¹ç›®å®ç°æ–¹æ³•åˆ†æ

#### 6.8.1 ä¼˜ç‚¹
1. **æ•°æ®å¤„ç†å®Œå–„**: åŒ…å«äº†å®Œæ•´çš„æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†æµç¨‹
2. **ç‰¹å¾å·¥ç¨‹ä¸°å¯Œ**: åˆ›å»ºäº†å¤šç§æ—¶é—´ç‰¹å¾ã€ç»Ÿè®¡ç‰¹å¾å’Œå°æ³¢ç‰¹å¾
3. **ä¿¡å·åˆ†è§£å…ˆè¿›**: ä½¿ç”¨CEEMDANå’Œè‡ªé€‚åº”æ²™ä¸é±¼ç®—æ³•ä¼˜åŒ–
4. **æ¨¡å‹æ¶æ„åˆ›æ–°**: ç»“åˆTCNã€å¤šå¤´æ³¨æ„åŠ›å’ŒBiGRUçš„ä¼˜åŠ¿
5. **ä¼˜åŒ–ç®—æ³•å…ˆè¿›**: ä½¿ç”¨è‡ªé€‚åº”æ²™ä¸é±¼ç¾¤ä¼˜åŒ–ç®—æ³•æå‡æ€§èƒ½
6. **è¯„ä¼°ä½“ç³»å®Œæ•´**: ä½¿ç”¨å¤šç§è¯„ä»·æŒ‡æ ‡å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½

#### 6.8.2 ä¸è¶³
1. **è®¡ç®—å¤æ‚åº¦**: æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒæ—¶é—´è¾ƒé•¿
2. **å‚æ•°è°ƒä¼˜**: éœ€è¦è¾ƒå¤šçš„è¶…å‚æ•°è°ƒä¼˜å·¥ä½œ
3. **æ•°æ®è¦æ±‚**: éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®æ¥è®­ç»ƒæ¨¡å‹
4. **å®æ—¶æ€§**: æ¨¡å‹é¢„æµ‹å¯èƒ½å­˜åœ¨ä¸€å®šçš„å»¶è¿Ÿ
5. **ä¾èµ–åº“å¤š**: éœ€è¦å®‰è£…å¤šä¸ªä¸“ä¸šåº“ï¼ˆå¦‚PyEMDã€pywtç­‰ï¼‰

#### 6.8.3 æ”¹è¿›å»ºè®®
1. **æ•°æ®æ‰©å……**: æ”¶é›†æ›´å¤šçš„å†å²æ•°æ®ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›
2. **ç‰¹å¾ä¼˜åŒ–**: è¿›ä¸€æ­¥ä¼˜åŒ–ç‰¹å¾é€‰æ‹©ï¼Œå»é™¤å†—ä½™ç‰¹å¾
3. **æ¨¡å‹é›†æˆ**: å°è¯•æ¨¡å‹é›†æˆæ–¹æ³•ï¼Œå¦‚Stackingæˆ–Blending
4. **å®æ—¶é¢„æµ‹**: å¼€å‘å®æ—¶é¢„æµ‹ç³»ç»Ÿï¼Œæ”¯æŒåœ¨çº¿é¢„æµ‹
5. **è½»é‡åŒ–**: å¼€å‘é€‚åˆè¾¹ç¼˜è®¡ç®—çš„è½»é‡åŒ–æ¨¡å‹

### 6.9 æ¨¡å—åŒ–é¡¹ç›®ä¼˜åŠ¿

#### 6.9.1 ä»£ç ç»„ç»‡ä¼˜åŠ¿
1. **æ¸…æ™°çš„æ¨¡å—åˆ’åˆ†**: 
   - æ•°æ®å¤„ç†ã€ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹è®­ç»ƒç­‰åŠŸèƒ½åˆ†åˆ«ç‹¬ç«‹
   - æ¯ä¸ªæ¨¡å—èŒè´£å•ä¸€ï¼Œä¾¿äºç†è§£å’Œç»´æŠ¤
   - æ”¯æŒç‹¬ç«‹å¼€å‘å’Œæµ‹è¯•

2. **æ˜“äºæ‰©å±•å’Œç»´æŠ¤**:
   - æ–°å¢åŠŸèƒ½åªéœ€åœ¨å¯¹åº”æ¨¡å—ä¸­æ·»åŠ 
   - ä¿®æ”¹æŸä¸ªåŠŸèƒ½ä¸å½±å“å…¶ä»–æ¨¡å—
   - ä»£ç å¤ç”¨æ€§é«˜ï¼Œé¿å…é‡å¤å¼€å‘

3. **ä¾¿äºå›¢é˜Ÿåä½œ**:
   - ä¸åŒå¼€å‘è€…å¯ä»¥ä¸“æ³¨äºä¸åŒæ¨¡å—
   - æ¨¡å—é—´æ¥å£æ¸…æ™°ï¼Œä¾¿äºé›†æˆ
   - æ”¯æŒå¹¶è¡Œå¼€å‘

#### 6.9.2 è¿è¡Œæ–¹å¼çµæ´»
1. **å¤šç§è¿è¡Œå…¥å£**:
   - `run.py`: æ ‡å‡†é¡¹ç›®å…¥å£
   - `src/main.py`: ç›´æ¥è¿è¡Œä¸»ç¨‹åº
   - æ”¯æŒIDEå’Œå‘½ä»¤è¡Œè¿è¡Œ

2. **æµ‹è¯•éªŒè¯å®Œå–„**:
   - ç¯å¢ƒéªŒè¯æµ‹è¯•
   - ä¾èµ–åŒ…æ£€æŸ¥
   - å¿«é€ŸåŠŸèƒ½æµ‹è¯•

3. **ç»“æœè¾“å‡ºè§„èŒƒ**:
   - å›¾è¡¨è¾“å‡ºåˆ° `results/plots/`
   - æ—¥å¿—è¾“å‡ºåˆ° `results/logs/`
   - æ¨¡å‹ä¿å­˜åˆ° `results/models/`

### 6.10 æœªæ¥å±•æœ›

#### 6.10.1 æŠ€æœ¯æ”¹è¿›æ–¹å‘
1. **æ¨¡å‹èåˆ**: æ¢ç´¢é›†æˆå­¦ä¹ æ–¹æ³•ï¼Œç»“åˆå¤šä¸ªæ¨¡å‹çš„ä¼˜åŠ¿
2. **åœ¨çº¿å­¦ä¹ **: å®ç°æ¨¡å‹çš„åœ¨çº¿æ›´æ–°å’Œè‡ªé€‚åº”å­¦ä¹ 
3. **å¤šæ­¥é¢„æµ‹**: æ‰©å±•ä¸ºå¤šæ­¥é¢„æµ‹ï¼Œæé«˜é¢„æµ‹çš„å®ç”¨æ€§
4. **ä¸ç¡®å®šæ€§é‡åŒ–**: å¼•å…¥é¢„æµ‹åŒºé—´ï¼Œé‡åŒ–é¢„æµ‹çš„ä¸ç¡®å®šæ€§
5. **è½»é‡åŒ–æ¨¡å‹**: å¼€å‘é€‚åˆè¾¹ç¼˜è®¡ç®—çš„è½»é‡åŒ–æ¨¡å‹

#### 6.10.2 åº”ç”¨æ‰©å±•æ–¹å‘
1. **å¤šé£åœºé¢„æµ‹**: æ‰©å±•åˆ°å¤šä¸ªé£ç”µåœºçš„è”åˆé¢„æµ‹
2. **æç«¯å¤©æ°”**: è€ƒè™‘æç«¯å¤©æ°”æ¡ä»¶ä¸‹çš„é¢„æµ‹å‡†ç¡®æ€§
3. **ç»æµæ€§åˆ†æ**: ç»“åˆç»æµå› ç´ ï¼Œä¼˜åŒ–å‘ç”µç­–ç•¥
4. **æ™ºèƒ½è°ƒåº¦**: ä¸ç”µç½‘è°ƒåº¦ç³»ç»Ÿé›†æˆï¼Œå®ç°æ™ºèƒ½è°ƒåº¦
5. **å®æ—¶é¢„æµ‹**: å¼€å‘å®æ—¶é¢„æµ‹ç³»ç»Ÿï¼Œæ”¯æŒåŠ¨æ€è°ƒåº¦å†³ç­–

#### 6.10.3 åº”ç”¨å‰æ™¯
1. **ç”µç½‘è°ƒåº¦**: ä¸ºç”µç½‘è°ƒåº¦æä¾›å‡†ç¡®çš„åŠŸç‡é¢„æµ‹
2. **è®¾å¤‡ç»´æŠ¤**: åŸºäºé¢„æµ‹ç»“æœä¼˜åŒ–è®¾å¤‡ç»´æŠ¤è®¡åˆ’
3. **ç»æµæ•ˆç›Š**: æé«˜é£åŠ›å‘ç”µçš„ç»æµæ•ˆç›Š
4. **èƒ½æºè§„åˆ’**: ä¸ºèƒ½æºè§„åˆ’æä¾›ç§‘å­¦ä¾æ®
5. **æ™ºèƒ½è¿ç»´**: å®ç°é£ç”µåœºçš„æ™ºèƒ½åŒ–è¿ç»´ç®¡ç†

## ä¸ƒã€é¡¹ç›®æ–‡ä»¶ç»“æ„

### 7.1 ç›®å½•ç»“æ„
```
é¡¹ç›®äºŒ/
â”œâ”€â”€ data/                    # æ•°æ®ç›®å½•
â”‚   â””â”€â”€ é¡¹ç›®2-0.csv         # åŸå§‹æ•°æ®æ–‡ä»¶
â”œâ”€â”€ docs/                    # æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ é¡¹ç›®è¯¦ç»†è¯´æ˜æ–‡æ¡£.md  # é¡¹ç›®è¯¦ç»†è¯´æ˜æ–‡æ¡£
â”‚   â””â”€â”€ PROJECT_STRUCTURE.md # é¡¹ç›®ç»“æ„è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ src/                     # æºä»£ç ç›®å½•
â”‚   â”œâ”€â”€ main.py             # ä¸»ç¨‹åºå…¥å£
â”‚   â”œâ”€â”€ utils/              # å·¥å…·å‡½æ•°æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py     # å·¥å…·åŒ…åˆå§‹åŒ–
â”‚   â”‚   â”œâ”€â”€ data_processing.py    # æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py # ç‰¹å¾å·¥ç¨‹æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ model_utils.py        # æ¨¡å‹å·¥å…·æ¨¡å—
â”‚   â”‚   â””â”€â”€ visualization.py      # å¯è§†åŒ–æ¨¡å—
â”‚   â””â”€â”€ models/             # æ¨¡å‹è®­ç»ƒæ¨¡å—
â”‚       â”œâ”€â”€ __init__.py     # æ¨¡å‹åŒ…åˆå§‹åŒ–
â”‚       â”œâ”€â”€ deep_learning.py      # æ·±åº¦å­¦ä¹ æ¨¡å‹
â”‚       â””â”€â”€ random_forest.py      # éšæœºæ£®æ—æ¨¡å‹
â”œâ”€â”€ results/                 # ç»“æœè¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ plots/              # å›¾è¡¨è¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ logs/               # æ—¥å¿—è¾“å‡ºç›®å½•
â”‚   â””â”€â”€ models/             # æ¨¡å‹ä¿å­˜ç›®å½•
â”œâ”€â”€ run.py                  # é¡¹ç›®è¿è¡Œå…¥å£
â”œâ”€â”€ requirements.txt        # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ environment.yml         # Anacondaç¯å¢ƒé…ç½®æ–‡ä»¶
â”œâ”€â”€ test_environment.py     # ç¯å¢ƒéªŒè¯æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ test_dependencies.py    # ä¾èµ–åŒ…æ£€æŸ¥æ–‡ä»¶
â”œâ”€â”€ test_quick_mode.py      # å¿«é€Ÿæµ‹è¯•æ–‡ä»¶
â””â”€â”€ README.md               # é¡¹ç›®ç®€ä»‹
```

### 7.2 æ ¸å¿ƒæ–‡ä»¶åŠŸèƒ½è¯´æ˜

#### 7.2.1 é¡¹ç›®å…¥å£æ–‡ä»¶
- **`run.py`**: é¡¹ç›®ä¸»å…¥å£ï¼Œè®¾ç½®Pythonè·¯å¾„å¹¶è°ƒç”¨ä¸»ç¨‹åº
- **`src/main.py`**: ä¸»ç¨‹åºé€»è¾‘ï¼Œåè°ƒå„ä¸ªæ¨¡å—å®Œæˆæ•´ä¸ªé¢„æµ‹æµç¨‹

#### 7.2.2 å·¥å…·å‡½æ•°æ¨¡å— (`src/utils/`)
- **`data_processing.py`**: æ•°æ®åŠ è½½ã€æ¸…æ´—ã€é¢„å¤„ç†åŠŸèƒ½
- **`feature_engineering.py`**: ç‰¹å¾åˆ›å»ºã€é€‰æ‹©ã€å˜æ¢åŠŸèƒ½
- **`model_utils.py`**: æ·±åº¦å­¦ä¹ æ¨¡å‹æ„å»ºã€åºåˆ—åˆ›å»ºã€ä¼˜åŒ–ç®—æ³•
- **`visualization.py`**: å›¾è¡¨ç»˜åˆ¶ã€ç»“æœå±•ç¤ºåŠŸèƒ½

#### 7.2.3 æ¨¡å‹è®­ç»ƒæ¨¡å— (`src/models/`)
- **`deep_learning.py`**: TCN-æ³¨æ„åŠ›-BiGRUæ¨¡å‹è®­ç»ƒ
- **`random_forest.py`**: éšæœºæ£®æ—æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–

#### 7.2.4 æµ‹è¯•éªŒè¯æ–‡ä»¶
- **`test_environment.py`**: éªŒè¯Pythonç¯å¢ƒå’ŒåŒ…å¯¼å…¥
- **`test_dependencies.py`**: æ£€æŸ¥æ‰€æœ‰ä¾èµ–åŒ…å®‰è£…çŠ¶æ€
- **`test_quick_mode.py`**: ä½¿ç”¨å°æ•°æ®é›†å¿«é€ŸéªŒè¯åŠŸèƒ½

#### 7.2.5 é…ç½®æ–‡ä»¶
- **`environment.yml`**: Anacondaç¯å¢ƒé…ç½®ï¼ŒåŒ…å«æ‰€æœ‰ä¾èµ–åŒ…
- **`requirements.txt`**: Pythonä¾èµ–åŒ…åˆ—è¡¨ï¼Œç”¨äºpipå®‰è£…

#### 7.2.6 è¾“å‡ºç›®å½• (`results/`)
- **`plots/`**: ä¿å­˜æ‰€æœ‰ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶
- **`logs/`**: ä¿å­˜è®­ç»ƒæ—¥å¿—å’Œé”™è¯¯ä¿¡æ¯
- **`models/`**: ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶

## å…«ã€å¿«é€Ÿå¼€å§‹

### 8.1 å¿«é€Ÿè¿è¡ŒæŒ‡å—

#### 8.1.1 ç¯å¢ƒå‡†å¤‡
```bash
# 1. åˆ›å»ºcondaç¯å¢ƒ
conda create -n wind_power_prediction python=3.8

# 2. æ¿€æ´»ç¯å¢ƒ
conda activate wind_power_prediction

# 3. å®‰è£…ä¾èµ–
conda env update -f environment.yml
```

#### 8.1.2 éªŒè¯ç¯å¢ƒ
```bash
# è¿è¡Œç¯å¢ƒéªŒè¯æµ‹è¯•
python test_environment.py

# æ£€æŸ¥ä¾èµ–åŒ…
python test_dependencies.py
```

#### 8.1.3 å¿«é€Ÿæµ‹è¯•
```bash
# ä½¿ç”¨å°æ•°æ®é›†å¿«é€ŸéªŒè¯åŠŸèƒ½
python test_quick_mode.py
```

#### 8.1.4 å®Œæ•´è¿è¡Œ
```bash
# è¿è¡Œå®Œæ•´é¡¹ç›®
python run.py
```

### 8.2 é¡¹ç›®è¿è¡Œæµç¨‹

#### 8.2.1 å®Œæ•´è¿è¡Œæµç¨‹
1. **ç¯å¢ƒå‡†å¤‡**: åˆ›å»ºcondaç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
2. **æ•°æ®åŠ è½½**: ä»`data/é¡¹ç›®2-0.csv`åŠ è½½åŸå§‹æ•°æ®
3. **æ•°æ®é¢„å¤„ç†**: æ¸…æ´—æ•°æ®ã€å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
4. **ç‰¹å¾å·¥ç¨‹**: åˆ›å»ºæ»åç‰¹å¾ã€æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾ã€å°æ³¢å˜æ¢ç‰¹å¾
5. **ç‰¹å¾é€‰æ‹©**: ä½¿ç”¨RFECVé€‰æ‹©æœ€ä¼˜ç‰¹å¾å­é›†
6. **ä¿¡å·åˆ†è§£**: CEEMDANåˆ†è§£å’Œæ ·æœ¬ç†µåˆ†æ
7. **æ¨¡å‹è®­ç»ƒ**: è®­ç»ƒTCN-æ³¨æ„åŠ›-BiGRUå’Œéšæœºæ£®æ—æ¨¡å‹
8. **æ¨¡å‹è¯„ä¼°**: è®¡ç®—å„ç§è¯„ä¼°æŒ‡æ ‡å¹¶å¯¹æ¯”æ¨¡å‹æ€§èƒ½
9. **ç»“æœè¾“å‡º**: ç”Ÿæˆå›¾è¡¨ã€ä¿å­˜æ¨¡å‹ã€è¾“å‡ºè¯„ä¼°ç»“æœ

#### 8.2.2 æ¨¡å—è°ƒç”¨å…³ç³»
```
run.py
â””â”€â”€ src/main.py
    â”œâ”€â”€ src/utils/data_processing.py (æ•°æ®åŠ è½½å’Œé¢„å¤„ç†)
    â”œâ”€â”€ src/utils/feature_engineering.py (ç‰¹å¾å·¥ç¨‹)
    â”œâ”€â”€ src/utils/visualization.py (ç›¸å…³æ€§åˆ†æå’Œå¯è§†åŒ–)
    â”œâ”€â”€ src/models/deep_learning.py (æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ)
    â””â”€â”€ src/models/random_forest.py (éšæœºæ£®æ—æ¨¡å‹è®­ç»ƒ)
```

#### 8.2.3 æ ¸å¿ƒæ–‡ä»¶
- **`run.py`**: é¡¹ç›®ä¸»å…¥å£ï¼Œè®¾ç½®è·¯å¾„å¹¶è°ƒç”¨ä¸»ç¨‹åº
- **`src/main.py`**: ä¸»ç¨‹åºé€»è¾‘ï¼Œåè°ƒå„ä¸ªæ¨¡å—
- **`src/utils/`**: å·¥å…·å‡½æ•°æ¨¡å—ï¼ŒåŒ…å«æ•°æ®å¤„ç†ã€ç‰¹å¾å·¥ç¨‹ç­‰
- **`src/models/`**: æ¨¡å‹è®­ç»ƒæ¨¡å—ï¼ŒåŒ…å«æ·±åº¦å­¦ä¹ å’Œéšæœºæ£®æ—æ¨¡å‹

#### 8.2.4 æµ‹è¯•æ–‡ä»¶
- **`test_environment.py`**: ç¯å¢ƒéªŒè¯æµ‹è¯•
- **`test_dependencies.py`**: ä¾èµ–åŒ…æ£€æŸ¥
- **`test_quick_mode.py`**: å¿«é€ŸåŠŸèƒ½æµ‹è¯•

#### 8.2.5 é…ç½®æ–‡ä»¶
- **`environment.yml`**: Anacondaç¯å¢ƒé…ç½®
- **`requirements.txt`**: Pythonä¾èµ–åŒ…åˆ—è¡¨

## ä¹ã€ä½¿ç”¨è¯´æ˜

### 9.1 ç¯å¢ƒå‡†å¤‡
æŒ‰ç…§ç¬¬å››ç« èŠ‚çš„éƒ¨ç½²æ­¥éª¤å‡†å¤‡ç¯å¢ƒã€‚

### 9.2 è¿è¡Œä»£ç 

#### æ–¹æ³•1: ä½¿ç”¨é¡¹ç›®å…¥å£è¿è¡Œï¼ˆæ¨èï¼‰
```bash
# æ¿€æ´»condaç¯å¢ƒ
conda activate wind_power_prediction

# åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•
cd [é¡¹ç›®è·¯å¾„]

# è¿è¡Œé¡¹ç›®
python run.py
```

#### æ–¹æ³•2: åœ¨PyCharmä¸­è¿è¡Œ
1. åœ¨PyCharmä¸­æ‰“å¼€é¡¹ç›®
2. ç¡®ä¿Pythonè§£é‡Šå™¨å·²æ­£ç¡®é…ç½®ä¸ºcondaç¯å¢ƒ
3. å³é”®ç‚¹å‡» `run.py` æ–‡ä»¶
4. é€‰æ‹© `Run 'run'`

#### æ–¹æ³•3: ç›´æ¥è¿è¡Œä¸»ç¨‹åº
```bash
# æ¿€æ´»condaç¯å¢ƒ
conda activate wind_power_prediction

# åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•
cd [é¡¹ç›®è·¯å¾„]

# ç›´æ¥è¿è¡Œä¸»ç¨‹åº
python src/main.py
```

#### æ–¹æ³•4: ä½¿ç”¨PyCharmè¿è¡Œé…ç½®
1. ç‚¹å‡»å·¥å…·æ çš„è¿è¡ŒæŒ‰é’®ï¼ˆç»¿è‰²ä¸‰è§’å½¢ï¼‰
2. æˆ–ä½¿ç”¨å¿«æ·é”® `Shift + F10` (Windows) / `Ctrl + R` (macOS)

### 9.3 ç»“æœæŸ¥çœ‹
è¿è¡Œå®Œæˆåï¼Œå°†ç”Ÿæˆä»¥ä¸‹ç»“æœï¼š

**å›¾è¡¨è¾“å‡º** (`results/plots/`):
- `correlation_heatmap.png` - ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾
- `training_history.png` - æ·±åº¦å­¦ä¹ è®­ç»ƒå†å²
- `optimization_convergence.png` - éšæœºæ£®æ—ä¼˜åŒ–æ”¶æ•›æ›²çº¿
- `model_comparison.png` - æ¨¡å‹å¯¹æ¯”ç»“æœ

**æ—¥å¿—è¾“å‡º** (`results/logs/`):
- è®­ç»ƒè¿‡ç¨‹æ—¥å¿—
- æ¨¡å‹è¯„ä¼°ç»“æœ
- é”™è¯¯å’Œè­¦å‘Šä¿¡æ¯

**æ¨¡å‹ä¿å­˜** (`results/models/`):
- è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶
- æ¨¡å‹å‚æ•°å’Œæƒé‡

**æ§åˆ¶å°è¾“å‡º**:
- æ•°æ®å¤„ç†è¿›åº¦
- æ¨¡å‹è®­ç»ƒè¿‡ç¨‹
- æ€§èƒ½è¯„ä¼°æŒ‡æ ‡
- æ¨¡å‹å¯¹æ¯”åˆ†æ

### 9.4 æ–°åŠŸèƒ½ä½¿ç”¨è¯´æ˜

#### 8.4.1 ä¿¡å·åˆ†è§£åŠŸèƒ½
- **CEEMDANåˆ†è§£**: ç¨‹åºä¼šè‡ªåŠ¨å¯¹åŠŸç‡æ•°æ®è¿›è¡ŒCEEMDANåˆ†è§£
- **æ ·æœ¬ç†µåˆ†æ**: è®¡ç®—æ¯ä¸ªIMFçš„æ ·æœ¬ç†µï¼Œè‡ªåŠ¨åˆå¹¶ä½ç†µIMF
- **ä¼˜åŒ–å‚æ•°**: ä½¿ç”¨è‡ªé€‚åº”æ²™ä¸é±¼ç®—æ³•ä¼˜åŒ–åˆ†è§£è¿‡ç¨‹

#### 8.4.2 å°æ³¢å˜æ¢ç‰¹å¾
- **è‡ªåŠ¨ç”Ÿæˆ**: ç¨‹åºä¼šè‡ªåŠ¨åˆ›å»ºè¿ç»­å°æ³¢å˜æ¢ç‰¹å¾
- **ç‰¹å¾é€‰æ‹©**: é€šè¿‡RFECVè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç‰¹å¾å­é›†
- **æ€§èƒ½æå‡**: å°æ³¢ç‰¹å¾æœ‰åŠ©äºæ•æ‰æ•°æ®çš„é¢‘åŸŸç‰¹æ€§

#### 8.4.3 å¹³ç¨³æ€§æ£€éªŒ
- **KPSSæ£€éªŒ**: è‡ªåŠ¨æ£€éªŒåŠŸç‡æ•°æ®çš„å¹³ç¨³æ€§
- **ç»“æœè¾“å‡º**: åœ¨æ§åˆ¶å°æ˜¾ç¤ºæ£€éªŒç»“æœå’Œç»“è®º
- **æ•°æ®è´¨é‡**: ä¸ºåç»­å¤„ç†æä¾›æ•°æ®ç‰¹æ€§åˆ†æ

### 9.5 æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 8.5.1 è®¡ç®—èµ„æº
- **å†…å­˜è¦æ±‚**: å»ºè®®16GBä»¥ä¸Šå†…å­˜ï¼Œç‰¹åˆ«æ˜¯å¤„ç†å°æ³¢å˜æ¢æ—¶
- **CPUè¦æ±‚**: å¤šæ ¸CPUå¯ä»¥åŠ é€Ÿç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹è®­ç»ƒ
- **GPUæ”¯æŒ**: æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒå»ºè®®ä½¿ç”¨GPUåŠ é€Ÿ

#### 8.5.2 å‚æ•°è°ƒæ•´
- **å°æ³¢å˜æ¢**: å¯ä»¥è°ƒæ•´scaleså‚æ•°æ§åˆ¶ç‰¹å¾æ•°é‡
- **CEEMDAN**: å¯ä»¥è°ƒæ•´max_imfå‚æ•°æ§åˆ¶åˆ†è§£ç²¾åº¦
- **ç‰¹å¾é€‰æ‹©**: å¯ä»¥è°ƒæ•´RFECVçš„stepå‚æ•°æ§åˆ¶é€‰æ‹©é€Ÿåº¦

## åã€å¸¸è§é—®é¢˜è§£ç­”

### 10.1 æ•°æ®åŠ è½½é—®é¢˜
**Q**: æ•°æ®æ–‡ä»¶æ— æ³•åŠ è½½æ€ä¹ˆåŠï¼Ÿ
**A**: ç¡®ä¿æ•°æ®æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼Œæ£€æŸ¥æ–‡ä»¶ç¼–ç æ ¼å¼ã€‚

### 10.2 å†…å­˜ä¸è¶³é—®é¢˜
**Q**: è®­ç»ƒæ—¶å‡ºç°å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
**A**: å¯ä»¥å‡å°‘æ•°æ®é‡ï¼Œæˆ–è€…ä½¿ç”¨æ›´å°çš„batch_sizeã€‚

### 10.3 è®­ç»ƒæ—¶é—´è¿‡é•¿é—®é¢˜
**Q**: LSTMæ¨¡å‹è®­ç»ƒæ—¶é—´è¿‡é•¿æ€ä¹ˆåŠï¼Ÿ
**A**: å¯ä»¥å‡å°‘epochsæ•°é‡ï¼Œæˆ–è€…ä½¿ç”¨GPUåŠ é€Ÿè®­ç»ƒã€‚

### 10.4 æ¨¡å‹æ€§èƒ½é—®é¢˜
**Q**: æ¨¡å‹æ€§èƒ½ä¸ç†æƒ³æ€ä¹ˆåŠï¼Ÿ
**A**: å¯ä»¥å°è¯•è°ƒæ•´è¶…å‚æ•°ï¼Œå¢åŠ ç‰¹å¾å·¥ç¨‹ï¼Œæˆ–è€…ä½¿ç”¨æ›´å¤æ‚çš„æ¨¡å‹ã€‚

### 10.5 æ–°è½¯ä»¶åŒ…ç›¸å…³é—®é¢˜

#### 10.5.1 PyEMDå®‰è£…é—®é¢˜
**Q**: PyEMDå®‰è£…å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
**A**: 
1. å…ˆå‡çº§pip: `pip install --upgrade pip`
2. å°è¯•: `pip install PyEMD --no-cache-dir`
3. å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œä½¿ç”¨conda: `conda install -c conda-forge pyemd`

#### 10.5.2 å°æ³¢å˜æ¢è®¡ç®—æ…¢
**Q**: å°æ³¢å˜æ¢ç‰¹å¾ç”Ÿæˆå¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ
**A**: 
1. å‡å°‘scaleså‚æ•°èŒƒå›´ï¼Œå¦‚æ”¹ä¸º`np.arange(1, 16)`
2. ä½¿ç”¨æ›´å°çš„æ•°æ®æ ·æœ¬è¿›è¡Œæµ‹è¯•
3. è€ƒè™‘ä½¿ç”¨GPUåŠ é€Ÿè®¡ç®—

#### 10.5.3 CEEMDANåˆ†è§£é—®é¢˜
**Q**: CEEMDANåˆ†è§£å‡ºç°é”™è¯¯æ€ä¹ˆåŠï¼Ÿ
**A**: 
1. æ£€æŸ¥æ•°æ®æ˜¯å¦åŒ…å«NaNæˆ–æ— ç©·å€¼
2. å‡å°‘max_imfå‚æ•°å€¼
3. ç¡®ä¿PyEMDç‰ˆæœ¬å…¼å®¹

#### 10.5.4 å†…å­˜ä¸è¶³é—®é¢˜
**Q**: è¿è¡Œæ–°åŠŸèƒ½æ—¶å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
**A**: 
1. å‡å°‘æ•°æ®é‡ï¼Œä½¿ç”¨æ•°æ®é‡‡æ ·
2. å…³é—­å…¶ä»–å ç”¨å†…å­˜çš„ç¨‹åº
3. è°ƒæ•´batch_sizeå‚æ•°
4. ä½¿ç”¨æ›´å°çš„ç‰¹å¾é›†
